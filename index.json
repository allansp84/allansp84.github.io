[{"authors":["admin"],"categories":null,"content":"I am a Postdoctoral Researcher at the University of Campinas (Unicamp), Brazil. I received a B.Sc. degree in Computer Science from the University of S√£o Paulo (USP), Brazil, an M.Sc. in Computer Science from the University of Campinas (Unicamp), Brazil, and a Ph.D. degree in Computer Science at the same university. A part of my doctoral was accomplished at the University of Notre Dame, USA. Currently, I am a member of the editorial board of the Forensic Science International: Reports, and also a member of the IEEE Information Forensics and Security Technical Committee (IFS-TC).\n Research interest  Pattern Recognition and Machine Learning Computer Vision Image and Video Analysis Computer Forensics Biometrics Content-based Image Retrieval Remote Sensing Sports Science   Applications of interest  Presentation attack in biometrics Text localization and recognition Depth estimation Segmentation Multimedia forensics Sports performance analysis Computational physiology \u0026amp; Healthy living     Education   PhD in Computer Science, 2018\nUniversity of Campinas (IC/Unicamp)\n   MSc in Computer Science, 2013\nUniversity of Campinas (IC/Unicamp)\n   BSc in Computer Science, 2011\nUniversity of S√£o Paulo (ICMC/USP)\n   News  Paper accepted in the Scientific Reports - Nature (2021) (More details soon) Interview (Unicamp Online Newspaper) (see more) Paper accepted in the IEEE Access (see more) üèÜ 1st Place Winner of the Upscaling Euro Data Cube COVID-19 Script Contest Organized by the European Space Agency (ESA) (see more) Paper accepted in the ICIP 2020 (see more) Paper accepted in the IEEE TIFS (see more) Paper accepted in the IEEE JSTARS (see more) Paper accepted in the Sensors (see more) Paper accepted in the IEEE Access (see more)    ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://allansp84.github.io/author/allan-pinto/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/allan-pinto/","section":"authors","summary":"I am a Postdoctoral Researcher at the University of Campinas (Unicamp), Brazil. I received a B.Sc. degree in Computer Science from the University of S√£o Paulo (USP), Brazil, an M.Sc. in Computer Science from the University of Campinas (Unicamp), Brazil, and a Ph.","tags":null,"title":"Allan Pinto","type":"authors"},{"authors":["A. Pinto","M. A. C√≥rdova","L. G. L. Decker","J. L. Flores-Campana","M. R. Souza","A. A. dos Santos","J. S. Concei√ß√£o","H. F. Gagliardi","D. C. Luvizon","R. d. S. Torres","H. Pedrini"],"categories":null,"content":"","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601510400,"objectID":"ab67b51b4d0b5f31b0457d23eeab90a4","permalink":"https://allansp84.github.io/publication/pinto-2020-icip/","publishdate":"2021-03-19T18:19:14.010569Z","relpermalink":"/publication/pinto-2020-icip/","section":"publication","summary":"Stereo vision is a growing topic in computer vision due to the innumerable opportunities and applications this technology offers for the development of modern solutions, such as virtual and augmented reality applications. To enhance the user's experience in three-dimensional virtual environments, the motion parallax estimation is a promising technique to achieve this objective. In this paper, we propose an algorithm for generating parallax motion effects from a single image, taking advantage of state-of-the-art instance segmentation and depth estimation approaches. This work also presents a comparison against such algorithms to investigate the trade-off between efficiency and quality of the parallax motion effects, taking into consideration a multi-task learning network capable of estimating instance segmentation and depth estimation at once. Experimental results and visual quality assessment indicate that the PyD-Net network (depth estimation) combined with Mask R-CNN or FBNet networks (instance segmentation) can produce parallax motion effects with good visual quality.","tags":["Computer Vision","Machine Learning","Segmentation","Object Detection"],"title":"Parallax Motion Effect Generation Through Instance Segmentation And Depth Estimation","type":"publication"},{"authors":[],"categories":[],"content":"","date":1600794384,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600794384,"objectID":"4c3386ff93537e6cfaefa5a1195715d0","permalink":"https://allansp84.github.io/project/presentatin-attack-detection/","publishdate":"2020-09-22T14:06:24-03:00","relpermalink":"/project/presentatin-attack-detection/","section":"project","summary":"","tags":[],"title":"Presentatin Attack Detection","type":"project"},{"authors":["D. Dias","A. Pinto","U. Dias","R. Lamparelli","G. Le Maire","R. d. S. Torres"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"5be03a6036d92220c47a385382186591","permalink":"https://allansp84.github.io/publication/dias-2020-jstars/","publishdate":"2021-03-19T18:19:14.008753Z","relpermalink":"/publication/dias-2020-jstars/","section":"publication","summary":"This article addresses the pixelwise classification problem based on temporal profiles, which are encoded in 2-D representations based on recurrence plots, Gramian angular/ difference fields, and Markov transition field. We propose a multirepresentational fusion scheme that exploits the complementary view provided by those time series representations and different data-driven feature extractors and classifiers. We validate our ensemble scheme in the problem related to the classification of eucalyptus plantations in remote sensing images. Achieved results demonstrate that our proposal overcomes recently proposed baselines, and now represents the new state-of-the-art classification solution for the target dataset.","tags":["Remote Sensing","Machine Learning","Fusion Information"],"title":"A Multirepresentational Fusion of Time Series for Pixelwise Classification","type":"publication"},{"authors":["Ewerton Silva","Ricardo da S Torres","Allan Pinto","Lin Tzy Li","Jos√© Eduardo S Vianna","Rodolfo Azevedo","Siome Goldenstein"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"60983b77e1048fbe278bf0105f98b73f","permalink":"https://allansp84.github.io/publication/silva-2020-sensors/","publishdate":"2021-03-19T18:19:14.010001Z","relpermalink":"/publication/silva-2020-sensors/","section":"publication","summary":"Energy and storage restrictions are relevant variables that software applications should be concerned about when running in low-power environments. In particular, computer vision (CV) applications exemplify well that concern, since conventional uniform image sensors typically capture large amounts of data to be further handled by the appropriate CV algorithms. Moreover, much of the acquired data are often redundant and outside of the application's interest, which leads to unnecessary processing and energy spending. In the literature, techniques for sensing and re-sampling images in non-uniform fashions have emerged to cope with these problems. In this study, we propose Application-Oriented Retinal Image Models that define a space-variant configuration of uniform images and contemplate requirements of energy consumption and storage footprints for CV applications. We hypothesize that our models might decrease energy consumption in CV tasks. Moreover, we show how to create the models and validate their use in a face detection/recognition application, evidencing the compromise between storage, energy, and accuracy.","tags":["Retinal Image Model","Computer Vision","Energy Consumption","Image Processing"],"title":"Application-oriented retinal image models for computer vision","type":"publication"},{"authors":["A. Pinto","S. Goldenstein","A. Ferreira","T. Carvalho","H. Pedrini","A. Rocha"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"893c7864eeb6b693517f89f1cf4f64ef","permalink":"https://allansp84.github.io/publication/pinto-2020-tifs/","publishdate":"2021-03-19T18:19:14.008021Z","relpermalink":"/publication/pinto-2020-tifs/","section":"publication","summary":"Presentation attack detection is a challenging problem that aims at exposing an impostor user seeking to deceive the authentication system. In facial biometrics systems, this kind of attack is performed using a photograph, video, or 3D mask containing the biometric information of a genuine identity. In this paper, we propose a novel approach to detecting face presentation attacks based on intrinsic properties of the scene such as albedo, depth, and reflectance properties of the facial surfaces, which were recovered through a shape-from-shading (SfS) algorithm. To extract meaningful patterns from the different maps obtained with the SfS algorithm, we designed a novel shallow CNN architecture for learning features useful to the presentation attack detection (PAD). We performed several experiments considering the intra- and inter-dataset evaluation protocols. The obtained results showed the effectiveness of the proposed method considering several types of photo- and video-based presentation attacks, and in the cross-sensor scenario, besides achieving competitive results  for the inter-dataset evaluation protocol.","tags":["Biometrics","Face Recognition","Presentation Attack Detection","Information Security","Digital Image Forensics"],"title":"Leveraging Shape, Reflectance and Albedo From Shading for Face Presentation Attack Detection","type":"publication"},{"authors":["Luis Gustavo Lorgus Decker.","Allan Pinto.","Jose Luis Flores Campana.","Manuel C√≥rdova Neira.","Andreza A. dos Santos.","Jhonatas S. Concei√ß√£o.","Marcus A. Angeloni.","Lin Tzy Li.","Ricardo da S. Torres."],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"a14db8ab12dc504cc55bc6ecc7a8778d","permalink":"https://allansp84.github.io/publication/decker-2020-visapp/","publishdate":"2021-03-19T18:19:14.009181Z","relpermalink":"/publication/decker-2020-visapp/","section":"publication","summary":"Multiple research initiatives have been reported to yield highly effective results for the text detection problem. However, most of those solutions are very costly, which hamper their use in several applications that rely on the use of devices with restrictive processing power, like smartwatches and mobile phones. In this paper, we address this issue by investigating the use of efficient object detection networks for this problem. We propose the combination of two light architectures, MobileNetV2 and Single Shot Detector (SSD), for the text detection problem. Experimental results in the ICDAR'11 and ICDAR'13 datasets demonstrate that our solution yields the best trade-off between effectiveness and efficiency and also achieved the state-of-the-art results in the ICDAR'11 dataset with an f-measure of 96.09%.","tags":["Text Localization","Text Recognition","Machine Learning","Computer Vision","Mobile Devices"],"title":"MobText: A Compact Method for Scene Text Localization","type":"publication"},{"authors":["J. L. Flores Campana","A. Pinto","M. Alberto C√≥rdova Neira","L. Gustavo Lorgus Decker","A. Santos","J. S. Concei√ß√£o","R. da Silva Torres"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"08e384fbefceffb4ebe8e54dcdd26070","permalink":"https://allansp84.github.io/publication/campana-2020-ieee-access/","publishdate":"2021-03-19T18:19:14.009385Z","relpermalink":"/publication/campana-2020-ieee-access/","section":"publication","summary":"Hundreds of text detection methods have been proposed, motivated by their widespread use in several applications. Despite the huge progress in the area, which includes even the use of sophisticated learning schemes, ad-hoc post-processing procedures are often employed to improve the text detection rate, by removing both false positives and negatives. Another issue refers to the lack of the use of the complementary views provided by different text detection methods. This paper aims to fill these gaps. We propose the use of a soft computing framework, based on genetic programming (GP), to guide the definition of suitable post-processing procedures through the combination of basic operators, which may be applied to improve detection results provided by multiple methods at the same time. Performed experiments in the widely used ICDAR 2011, ICDAR 2013, and ICDAR 2015 datasets demonstrate that our GP-based approach leads to F1 effectiveness gains up to 5.1 percentage points, when compared to several baselines.","tags":["Text Localization","Text Recognition","Machine Learning","Computer Vision","Mobile Devices"],"title":"On the Fusion of Text Detection Results: A Genetic Programming Approach","type":"publication"},{"authors":["M. C√≥rdova","A. Pinto","H. Pedrini","R. d. S. Torres"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"6175e8bbffbb945918d89f1bcbb1122c","permalink":"https://allansp84.github.io/publication/cordova-2020-ieee-access/","publishdate":"2021-03-19T18:19:14.010806Z","relpermalink":"/publication/cordova-2020-ieee-access/","section":"publication","summary":"Scene text detection has become an important field in the computer vision area due to the increasing number of applications. This is a very challenging problem as textual elements are commonly found in ‚Äúnoisy‚Äù and complex natural scenes. Another issue refers to the presence of texts encoded into different languages within the same image. State-of-the-art solutions rely on the use of deep neural network approaches or even ensembles of them. However, such solutions are associated with ‚Äúheavy‚Äù models, which are computationally expensive in terms of memory and storage footprints, which hampers their use in real-time mobile applications. In this work, we introduce Pelee-Text++, a lightweight neural network architecture for multi-lingual multi-oriented scene text detection, especially tailored to running on devices with computational restrictions. Additionally, to the best of our knowledge, this is the first work to evaluate the performance of text detection methods in commercial smartphones. Over this scenario, Pelee-Text++ processes 2.94 frames per second and it is the only evaluated approach that did not cause memory issues on smartphones, even using an input image of  $1024times 1024$  pixels. Our proposal achieves a promising trade-off between efficiency and effectiveness, with a model size of 27 Megabytes and F-measure of 91.20%, 85.78%, 81.72%, 80.30%, 82.53% and 66.51% on ICDAR 2011, ICDAR 2013, ICDAR 2015, MSRA-TD500, ReCTS 2019 and Multi-lingual 2019 datasets, respectively.","tags":["Performance evaluation;Training;Computational modeling;Neural networks;Random access memory;Proposals;Smart phones;Text detection;mobile-network;mobile devices;multi-oriented text;multi-lingual;convolutional neural network"],"title":"Pelee-Text++: A Tiny Neural Network for Scene Text Detection","type":"publication"},{"authors":["Alexandre G. Almeida","Murilo Merlin","Allan Pinto","Ricardo da S. Torres","Sergio A. Cunha"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"1bfbdf4c3451869a4888306ed3555757","permalink":"https://allansp84.github.io/publication/almeida-2020-ijpas/","publishdate":"2021-03-19T18:19:14.008379Z","relpermalink":"/publication/almeida-2020-ijpas/","section":"publication","summary":"The aim of this study was to identify the most relevant variables to characterise the performance level of the teams through Men's World Championships (2007-2019). Forty-seven attributes from match-related statistics and characteristics of players were analysed in 168 participant teams. Descriptive discriminant analysis classified correctly 69.6% of the cases and selected the height of players, 9-m efficiency, international matches disputed, wing efficiency, blocked shots, 7-m goalkeeper efficiency and 2-min suspensions which were the most relevant indicators. Top-Elite was significantly different (one-way ANOVA) from Middle- and Low-Elite in all variables selected, except for 7-m goalkeeper efficiency. Linear regression shows that wing efficiency and blocked shots were the only variables with a tendency of changes through seven editions. The best teams have the tallest players and with more international matches disputed, were most efficient in 9-m and wing finalisations and block more shots in defence. These findings may guide scientists and sports trainers to select players, prescribe training procedures, analyse opponents and establish match strategies with special attention to these variables.","tags":["Sports Sciences","Performance Analysis"],"title":"Performance-level indicators of male elite handball teams","type":"publication"},{"authors":["Luis A. M. Pereira","Allan Pinto","Fernanda A. Andal√≥","Alexandre M. Ferreira","Bahram Lavi","Aurea Soriano-Vargas","Marcos V. M. Cirne","Anderson Rocha"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"29fafa6ed732a16f1b0c690110f67056","permalink":"https://allansp84.github.io/publication/pereira-2020-springer/","publishdate":"2021-03-19T18:19:14.00856Z","relpermalink":"/publication/pereira-2020-springer/","section":"publication","summary":"Biometric systems are prevalent in access control but are vulnerable to frauds. A typical attempt of violating them is through presentation attacks, in which synthetic data is directly presented to an acquisition sensor to deceive these systems. A well-designed biometric system should have a presentation attack detection (PAD) module. A fruitful way to perform PAD is to model properties of peculiar traits (artifacts) in synthetic data. Studies have been advocating for approaches that seek to model the artifacts automatically from data (data-driven), achieving state-of-the-art results in PAD. However, the following questions arise from this literature: Which approaches are the state of the art? When do these approaches fail? How can such approaches complement the proposed ones based on human knowledge on PAD? How robust are these approaches under cross-dataset scenarios? Are these approaches robust against new attack types (e.g., face morphing)? Do these methods provide other ways to perform PAD, for example, using open-set classifiers rather than the classical binary formulation? Are these methods applicable to the multi-biometric setting? In this chapter, we address these questions through a literature review, focusing on three biometric modalities: face, fingerprint, and iris.","tags":["Biometrics","Face Recognition","Fingerprint Recognition","Iris Recognition","Information Security","Digital Image Forensics"],"title":"The Rise of Data-Driven Models in Presentation Attack Detection","type":"publication"},{"authors":["M. A. C√≥rdova","L. G. L. Decker","J. L. Flores-Campana","A. A. dos Santos","J. S. Concei√ß√£o","A. Pinto","H. Pedrini","R. da S. Torres"],"categories":null,"content":"","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575158400,"objectID":"d9c162aeac2333290c471f681d275801","permalink":"https://allansp84.github.io/publication/cordova-2019-icmla/","publishdate":"2021-03-19T18:19:14.008936Z","relpermalink":"/publication/cordova-2019-icmla/","section":"publication","summary":"Nowadays, scene text detection has received a lot of attention due to its complexity given variations in terms of orientations, font size, aspect ratio, and natural backgrounds. In this vein, several deep neural networks have been proposed to deal with this challenging problem. However, such networks produce \"heavy\" models, hampering their use in applications running in devices with computational constraints. Additionally, few works are focused on the detection of multi-oriented and/or multi-lingual text. Herein, we propose an end-to-end tiny convolutional neural network for multi-oriented multi-lingual scene text called Pelee- Text. Experimental results show that Pelee-Text is at least 3 times smaller than its counterparts with a speed of 2.93 and 18.64 frames per second for its multi-scale and 768-scale versions, respectively. Moreover, in terms of F-measure, our method achieved competitive results on four well-known datasets, i.e., ICDAR'2011 (90.96%), ICDAR'2013 (85.24%), ICDAR'2015 (80.08%), and MSRA-TD500 (80.90%).","tags":["Text Localization","Text Recognition","Machine Learning","Computer Vision","Mobile Devices"],"title":"Pelee-Text: A Tiny Convolutional Neural Network for Multi-oriented Scene Text Detection","type":"publication"},{"authors":["A. Kuehlkamp","A. Pinto","A. Rocha","K. W. Bowyer","A. Czajka"],"categories":null,"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"e9999d6f27136c85735a101177c95316","permalink":"https://allansp84.github.io/publication/kuehlkamp-2019-tifs/","publishdate":"2021-03-19T18:19:14.007805Z","relpermalink":"/publication/kuehlkamp-2019-tifs/","section":"publication","summary":"The adoption of large-scale iris recognition systems around the world has brought to light the importance of detecting presentation attack images (textured contact lenses and printouts). This paper presents a new approach in iris presentation attack detection (PAD) by exploring combinations of convolutional neural networks (CNNs) and transformed input spaces through binarized statistical image features (BSIFs). Our method combines lightweight CNNs to classify multiple BSIF views of the input image. Following explorations on complementary input spaces leading to more discriminative features to detect presentation attacks, we also propose an algorithm to select the best (and most discriminative) predictors for the task at hand. An ensemble of predictors makes use of their expected individual performances to aggregate their results into a final prediction. Results show that this technique improves on the current state of the art in iris PAD, outperforming the winner of LivDet-Iris 2017 competition both for intra- and cross-dataset scenarios, and illustrating the very difficult nature of the cross-dataset scenario.","tags":["Biometrics","Iris Recognition","Presentation Attack Detection","Information Security","Digital Image Forensics"],"title":"Ensemble of Multi-View Learning Classifiers for Cross-Domain Iris Presentation Attack Detection","type":"publication"},{"authors":["Jhonatas Concei√ß√£o","Allan Pinto","Luis Decker","Jose Luis Campana","Manuel Neira","Andrezza dos Santos","Helio Pedrini","Ricardo Torres"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"13c252bd27771259d4ec7d1cc2bfa6f7","permalink":"https://allansp84.github.io/publication/conceicao-2019-sibgrapi/","publishdate":"2021-03-19T18:19:14.009581Z","relpermalink":"/publication/conceicao-2019-sibgrapi/","section":"publication","summary":"Localiza√É¬ß√É¬£o e Reconhecimento de texto em cena √É¬© um t√É¬≥pico em vis√É¬£o computacional que objetiva delimitar regi√É¬µes candidatas em uma imagem de entrada contendo texto em cena. O desafio desta pesquisa consiste em desenvolver detectores capazes de lidar com diversas fontes de variabilidade tais como tamanho de fontes e cor, fundo complexo, texto em diferentes linguagens, entre outros. Este trabalho apresenta uma compara√É¬ß√É¬£o entre estrat√É¬©gias para a constru√É¬ß√É¬£o de modelos de classifica√É¬ß√É¬£o baseados em Redes Neurais Convolucionais, para detectar elementos textuais em m√É¬∫ltiplas linguagens em imagens, tais como: (i) modelo de classifica√É¬ß√É¬£o constru√É¬≠do em um cen√É¬°rio multil√É¬≠ngue; e (ii) modelo de classifica√É¬ß√É¬£o constru√É¬≠do em um cen√É¬°rio de linguagem espec√É¬≠fica. Os experimentos conduzidos neste trabalho indicam que modelos de linguagem espec√É¬≠fica superam os modelos treinados em um cen√É¬°rio multil√É¬≠ngue, apresentando uma melhoria de 14.79%, 8.94%, e 11.43%, em termos de precis√É¬£o, revoca√É¬ß√É¬£o e f-measure, respectivamente.","tags":["Text Localization","Text Recognition","Machine Learning","Computer Vision","Mobile Devices"],"title":"Multi-Lingual Text Localization via Language-Specific Convolutional Neural Networks","type":"publication"},{"authors":["D. Moreira","A. Bharati","J. Brogan","A. Pinto","M. Parowski","K. W. Bowyer","P. J. Flynn","A. Rocha","W. J. Scheirer"],"categories":null,"content":"","date":1543622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543622400,"objectID":"c00ff14737bd846a2059c89cd20ab314","permalink":"https://allansp84.github.io/publication/moreira-2018-tip/","publishdate":"2021-03-19T18:19:14.007582Z","relpermalink":"/publication/moreira-2018-tip/","section":"publication","summary":"Prior art has shown it is possible to estimate, through image processing and computer vision techniques, the types and parameters of transformations that have been applied to the content of individual images to obtain new images. Given a large corpus of images and a query image, an interesting further step is to retrieve the set of original images whose content is present in the query image, as well as the detailed sequences of transformations that yield the query image, given the original images. This is a problem that recently has received the name of image provenance analysis. In these times of public media manipulation (e.g., fake news and meme sharing), obtaining the history of image transformations is relevant for fact checking and authorship verification, among many other applications. This paper presents an end-to-end processing pipeline for image provenance analysis which works at real-world scale. It employs a cutting-edge image filtering solution that is custom-tailored for the problem at hand, as well as novel techniques for obtaining the provenance graph that expresses how the images, as nodes, are ancestrally connected. A comprehensive set of experiments for each stage of the pipeline is provided, comparing the proposed solution with the state-of-the-art results, employing previously published data sets. In addition, this paper introduces a new data set of real-world provenance cases from the social media site Reddit, along with baseline results.","tags":["Graph Theory","Image Filtering","Image Retrieval","Social Networking","Image Provenance Analysis","Digital Image Forensics","Multimedia Forensics","Image Phylogeny"],"title":"Image Provenance Analysis at Scale","type":"publication"},{"authors":["Allan Pinto"],"categories":null,"content":"","date":1535760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535760000,"objectID":"ac0e043659f574efc67aed6662cd3800","permalink":"https://allansp84.github.io/publication/pinto-2018-ph-d-thesis/","publishdate":"2021-03-19T18:19:14.009783Z","relpermalink":"/publication/pinto-2018-ph-d-thesis/","section":"publication","summary":"Recent advances in biometrics, information forensics, and security have improved the recognition effectiveness of biometric systems. However, an ever-growing challenge is the vulnerability of such systems against presentation attacks, in which impostor users create synthetic samples from the original biometric information of a legitimate user and show them to the acquisition sensor seeking to authenticate themselves as legitimate users. Depending on the trait used by the biometric authentication, the attack types vary with the type of material used to build the synthetic samples. For instance, in facial biometric systems, an attempted attack is characterized by the type of material the impostor uses such as a photograph, a digital video, or a 3D mask with the facial information of a target user. In iris-based biometrics, presentation attacks can be accomplished with printout photographs or with contact lenses containing the iris patterns of a target user or even synthetic texture patterns. In fingerprint biometric systems, impostor users can deceive the authentication process using replicas of the fingerprint patterns built with synthetic materials such as latex, play-doh, silicone, among others. This research aimed at developing presentation attack detection (PAD) solutions whose objective is to detect attempted attacks considering different attack types, in each modality. The lines of investigation presented in this thesis aimed at devising and developing representations based on spatial, temporal and spectral information from noise signature, intrinsic properties of the biometric data (e.g., albedo, reflectance, and depth maps), and supervised feature learning techniques, taking into account different testing scenarios including cross-sensor, intra-, and inter-dataset scenarios. The main findings and contributions presented in this thesis include: the creation of a large and publicly available benchmark containing 17K videos of presentation attacks and bona-fide presentations simulations in a facial biometric system, whose collect were formally authorized by the Research Ethics Committee at Unicamp; the development of novel approaches to modeling and analysis of extrinsic properties of biometric samples related to artifacts added during the manufacturing of the synthetic samples and their capture by the acquisition sensor, whose results were superior to several approaches published in the literature that use traditional methods for image analysis (e.g., texture-based analysis); the investigation of an approach based on the analysis of intrinsic properties of faces, estimated from the information of shadows present on their surface; and the investigation of different approaches to automatically learning representations related to our problem, whose results were superior or competitive to state-of-the-art methods for the biometric modalities considered in this thesis. We also considered in this research the design of efficient neural networks with shallow architectures capable of learning characteristics related to our problem from small sets of data available to develop and evaluate PAD solutions.","tags":["Biometrics","Face Recognition","Fingerprint Recognition","Iris Recognition","Information Security","Digital Image Forensics"],"title":"Analysis of intrinsic and extrinsic properties of biometric samples for presentation attack detection","type":"publication"},{"authors":["Allan Pinto","Helio Pedrini","Michael Krumdick","Benedict Becker","Adam Czajka","Kevin W. Bowyer","Anderson Rocha"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"1e0a3e86528e72563c52ee940b63866b","permalink":"https://allansp84.github.io/publication/pinto-2018-crc-press/","publishdate":"2021-03-19T18:19:14.007384Z","relpermalink":"/publication/pinto-2018-crc-press/","section":"publication","summary":"This chapter explores data-driven approaches to presentation attack detection for three biometric modalities: face, iris, and fingerprint. The primary aim of this chapter is to show how pretrained deep neural networks can be used to build classifiers that can distinguish between authentic images of faces, irises, and fingerprints and their static imitations. The most important, publicly available benchmarks representing various attack types were used in a unified presentation attack detection framework in both same-dataset and cross-dataset experiments. The pretrained VGG neural networks, being the core of this solution, tuned independently for each modality and each dataset present almost perfect accuracy for all three biometric techniques. In turn, low-classification accuracies achieved in cross-dataset evaluations show that models based on deep neural networks are sensitive not only to features specific to biometric imitations, but also to dataset-specific properties of samples. Thus, such models can provide a rapid solution in scenarios in which properties of imitations can be predicted but appropriate feature engineering is difficult. However, these models will perform worse if the properties of imitations being detected are unknown. This chapter also includes a current literature review summarizing up-to-date data-driven solutions to face, iris and finger liveness detection.","tags":["Biometrics","Face Recognition","Fingerprint Recognition","Iris Recognition","Presentation Attack Detection","Information Security","Digital Image Forensics"],"title":"Deep Learning in Biometrics","type":"publication"},{"authors":["A. Pinto","D. Moreira","A. Bharati","J. Brogan","K. Bowyer","P. Flynn","W. Scheirer","A. Rocha"],"categories":null,"content":"","date":1504224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504224000,"objectID":"9e2fdc6a6635c24cb1e9b2f3062c9581","permalink":"https://allansp84.github.io/publication/pinto-2017-icip/","publishdate":"2021-03-19T18:19:14.006671Z","relpermalink":"/publication/pinto-2017-icip/","section":"publication","summary":"Departing from traditional digital forensics modeling, which seeks to analyze single objects in isolation, multimedia phylogeny analyzes the evolutionary processes that influence digital objects and collections over time. One of its integral pieces is provenance filtering, which consists of searching a potentially large pool of objects for the most related ones with respect to a given query, in terms of possible ancestors (donors or contributors) and descendants. In this paper, we propose a two-tiered provenance filtering approach to find all the potential images that might have contributed to the creation process of a given query q. In our solution, the first (coarse) tier aims to find the most likely \"host\" images - the major donor or background - contributing to a composite/doctored image. The search is then refined in the second tier, in which we search for more specific (potentially small) parts of the query that might have been extracted from other images and spliced into the query image. Experimental results with a dataset containing more than a million images show that the two-tiered solution underpinned by the context of the query is highly useful for solving this difficult task.","tags":["Graph Theory","Image Filtering","Image Retrieval","Social Networking","Image Provenance Analysis","Digital Image Forensics","Multimedia Forensics","Image Phylogeny"],"title":"Provenance filtering for multimedia phylogeny","type":"publication"},{"authors":["J. Brogan","P. Bestagini","A. Bharati","A. Pinto","D. Moreira","K. Bowyer","P. Flynn","A. Rocha","W. Scheirer"],"categories":null,"content":"","date":1504224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504224000,"objectID":"08b31a76783e5dcf77a319a757264584","permalink":"https://allansp84.github.io/publication/brogan-2017-icip/","publishdate":"2021-03-19T18:19:14.006907Z","relpermalink":"/publication/brogan-2017-icip/","section":"publication","summary":"As image tampering becomes ever more sophisticated and commonplace, the need for image forensics algorithms that can accurately and quickly detect forgeries grows. In this paper, we revisit the ideas of image querying and retrieval to provide clues to better localize forgeries. We propose a method to perform large-scale image forensics on the order of one million images using the help of an image search algorithm and database to gather contextual clues as to where tampering may have taken place. In this vein, we introduce five new strongly invariant image comparison methods and test their effectiveness under heavy noise, rotation, and color space changes. Lastly, we show the effectiveness of these methods compared to passive image forensics using Nimble [1], a new, state-of-the-art dataset from the National Institute of Standards and Technology (NIST).","tags":["Graph Theory","Image Filtering","Image Retrieval","Social Networking","Image Provenance Analysis","Digital Image Forensics","Multimedia Forensics","Image Phylogeny"],"title":"Spotting the difference: Context retrieval and analysis for improved forgery detection and localization","type":"publication"},{"authors":["A. Bharati","D. Moreira","A. Pinto","J. Brogan","K. Bowyer","P. Flynn","W. Scheirer","A. Rocha"],"categories":null,"content":"","date":1504224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504224000,"objectID":"270ce70fde6b362fc04565b5aed9ec88","permalink":"https://allansp84.github.io/publication/bharati-2017-icip/","publishdate":"2021-03-19T18:19:14.007164Z","relpermalink":"/publication/bharati-2017-icip/","section":"publication","summary":"Deriving relationships between images and tracing back their history of modifications are at the core of Multimedia Phylogeny solutions, which aim to combat misinformation through doctored visual media. Nonetheless, most recent image phylogeny solutions cannot properly address cases of forged composite images with multiple donors, an area known as multiple parenting phylogeny (MPP). This paper presents a preliminary undirected graph construction solution for MPP, without any strict assumptions. The algorithm is underpinned by robust image representative keypoints and different geometric consistency checks among matching regions in both images to provide regions of interest for direct comparison. The paper introduces a novel technique to geometrically filter the most promising matches as well as to aid in the shared region localization task. The strength of the approach is corroborated by experiments with real-world cases, with and without image distractors (unrelated cases).","tags":["Graph Theory","Image Filtering","Image Retrieval","Social Networking","Image Provenance Analysis","Digital Image Forensics","Multimedia Forensics","Image Phylogeny"],"title":"U-Phylogeny: Undirected provenance graph construction in the wild","type":"publication"},{"authors":["A. Pinto","H. Pedrini","W. Robson Schwartz","A. Rocha"],"categories":null,"content":"","date":1448928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448928000,"objectID":"69db5961429c2564e572014c32525a65","permalink":"https://allansp84.github.io/publication/pinto-2015-tip/","publishdate":"2021-03-19T18:19:14.006446Z","relpermalink":"/publication/pinto-2015-tip/","section":"publication","summary":"Despite important recent advances, the vulnerability of biometric systems to spoofing attacks is still an open problem. Spoof attacks occur when impostor users present synthetic biometric samples of a valid user to the biometric system seeking to deceive it. Considering the case of face biometrics, a spoofing attack consists in presenting a fake sample (e.g., photograph, digital video, or even a 3D mask) to the acquisition sensor with the facial information of a valid user. In this paper, we introduce a low cost and software-based method for detecting spoofing attempts in face recognition systems. Our hypothesis is that during acquisition, there will be inevitable artifacts left behind in the recaptured biometric samples allowing us to create a discriminative signature of the video generated by the biometric sensor. To characterize these artifacts, we extract time-spectral feature descriptors from the video, which can be understood as a low-level feature descriptor that gathers temporal and spectral information across the biometric sample and use the visual codebook concept to find mid-level feature descriptors computed from the low-level ones. Such descriptors are more robust for detecting several kinds of attacks than the low-level ones. The experimental results show the effectiveness of the proposed method for detecting different types of attacks in a variety of scenarios and data sets, including photos, videos, and 3D masks.","tags":["Biometrics","Face Recognition","Presentation Attack Detection","Information Security","Digital Image Forensics"],"title":"Face Spoofing Detection Through Visual Codebooks of Spectral Temporal Cubes","type":"publication"},{"authors":["A. Pinto","W. Robson Schwartz","H. Pedrini","A. de Rezende Rocha"],"categories":null,"content":"","date":1430438400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430438400,"objectID":"732abf2100502c68356ab9ff6c27f249","permalink":"https://allansp84.github.io/publication/pinto-2015-tifs/","publishdate":"2021-03-19T18:19:14.006224Z","relpermalink":"/publication/pinto-2015-tifs/","section":"publication","summary":"Spoofing attacks or impersonation can be easily accomplished in a facial biometric system wherein users without access privileges attempt to authenticate themselves as valid users, in which an impostor needs only a photograph or a video with facial information of a legitimate user. Even with recent advances in biometrics, information forensics and security, vulnerability of facial biometric systems against spoofing attacks is still an open problem. Even though several methods have been proposed for photo-based spoofing attack detection, attacks performed with videos have been vastly overlooked, which hinders the use of the facial biometric systems in modern applications. In this paper, we present an algorithm for video-based spoofing attack detection through the analysis of global information which is invariant to content, since we discard video contents and analyze content-independent noise signatures present in the video related to the unique acquisition processes. Our approach takes advantage of noise signatures generated by the recaptured video to distinguish between fake and valid access videos. For that, we use the Fourier spectrum followed by the computation of video visual rhythms and the extraction of different characterization methods. For evaluation, we consider the novel unicamp video-attack database, which comprises 17 076 videos composed of real access and spoofing attack videos. In addition, we evaluate the proposed method using the replay-attack database, which contains photo-based and video-based face spoofing attacks.","tags":["Biometrics","Face Recognition","Presentation Attack Detection","Information Security","Digital Image Forensics"],"title":"Using Visual Rhythms for Detecting Video-Based Facial Spoof Attacks","type":"publication"},{"authors":["D. Menotti","G. Chiachia","A. Pinto","W. Robson Schwartz","H. Pedrini","A. Xavier Falcao","A. Rocha"],"categories":null,"content":"","date":1427846400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1427846400,"objectID":"6e655116b88a1a21ea863ac6d9907c52","permalink":"https://allansp84.github.io/publication/menotti-2015-tifs/","publishdate":"2021-03-19T18:19:14.005994Z","relpermalink":"/publication/menotti-2015-tifs/","section":"publication","summary":"Biometrics systems have significantly improved person identification and authentication, playing an important role in personal, national, and global security. However, these systems might be deceived (or spoofed) and, despite the recent advances in spoofing detection, current solutions often rely on domain knowledge, specific biometric reading systems, and attack types. We assume a very limited knowledge about biometric spoofing at the sensor to derive outstanding spoofing detection systems for iris, face, and fingerprint modalities based on two deep learning approaches. The first approach consists of learning suitable convolutional network architectures for each domain, whereas the second approach focuses on learning the weights of the network via back propagation. We consider nine biometric spoofing benchmarks - each one containing real and fake samples of a given biometric modality and attack type - and learn deep representations for each benchmark by combining and contrasting the two learning approaches. This strategy not only provides better comprehension of how these approaches interplay, but also creates systems that exceed the best known results in eight out of the nine benchmarks. The results strongly indicate that spoofing detection systems based on convolutional networks can be robust to attacks already known and possibly adapted, with little effort, to image-based attacks that are yet to come.","tags":["Biometrics","Face Recognition","Fingerprint Recognition","Iris Recognition","Presentation Attack Detection","Information Security","Digital Image Forensics"],"title":"Deep Representations for Iris, Face, and Fingerprint Spoofing Detection","type":"publication"},{"authors":["Allan Pinto"],"categories":null,"content":"","date":1380585600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1380585600,"objectID":"c7243ab845fb18aaf279014b1766aa25","permalink":"https://allansp84.github.io/publication/pinto-2013-master-dissertation/","publishdate":"2021-03-19T18:19:14.010378Z","relpermalink":"/publication/pinto-2013-master-dissertation/","section":"publication","summary":"","tags":["Biometrics","Face Recognition","Fingerprint Recognition","Iris Recognition","Information Security","Digital Image Forensics"],"title":"A countermeasure method for video-based face spoofing attacks","type":"publication"},{"authors":["I. Chingovska","A. Pinto","H. Pedrini","W. S. Schwartz","A. Rocha","A. Anjos","S. Marcel \textitet al."],"categories":null,"content":"","date":1370044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1370044800,"objectID":"ce64520ad62c3e50b0bc5ea5aec9d3b0","permalink":"https://allansp84.github.io/publication/chingovska-2013-icb/","publishdate":"2021-03-19T18:19:14.00576Z","relpermalink":"/publication/chingovska-2013-icb/","section":"publication","summary":"As a crucial security problem, anti-spoofing in biometrics, and particularly for the face modality, has achieved great progress in the recent years. Still, new threats arrive inform of better, more realistic and more sophisticated spoofing attacks. The objective of the 2nd Competition on Counter Measures to 2D Face Spoofing Attacks is to challenge researchers to create counter measures effectively detecting a variety of attacks. The submitted propositions are evaluated on the Replay-Attack database and the achieved results are presented in this paper.","tags":["Biometrics","Face Recognition","Presentation Attack Detection","Information Security","Digital Image Forensics"],"title":"The 2nd competition on counter measures to 2D face spoofing attacks","type":"publication"},{"authors":["A. da Silva Pinto","H. Pedrini","W. Schwartz","A. Rocha"],"categories":null,"content":"","date":1343779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1343779200,"objectID":"96bca68fde78e4dea4fc390d43507347","permalink":"https://allansp84.github.io/publication/pinto-2012-sibgrapi/","publishdate":"2021-03-19T18:19:14.005434Z","relpermalink":"/publication/pinto-2012-sibgrapi/","section":"publication","summary":"Recent advances on biometrics, information forensics, and security have improved the accuracy of biometric systems, mainly those based on facial information. However, an ever-growing challenge is the vulnerability of such systems to impostor attacks, in which users without access privileges try to authenticate themselves as valid users. In this work, we present a solution to video-based face spoofing to biometric systems. Such type of attack is characterized by presenting a video of a real user to the biometric system. To the best of our knowledge, this is the first attempt of dealing with video-based face spoofing based in the analysis of global information that is invariant to video content. Our approach takes advantage of noise signatures generated by the recaptured video to distinguish between fake and valid access. To capture the noise and obtain a compact representation, we use the Fourier spectrum followed by the computation of the visual rhythm and extraction of the gray-level co-occurrence matrices, used as feature descriptors. Results show the effectiveness of the proposed approach to distinguish between valid and fake users for video-based spoofing with near-perfect classification results.","tags":["Biometrics","Face Recognition","Presentation Attack Detection","Information Security","Digital Image Forensics"],"title":"Video-Based Face Spoofing Detection through Visual Rhythm Analysis","type":"publication"},{"authors":["Tiago Carvalho","A. Pinto","E. Silva","F. O. Costa","G. R. Pinheiro"," A.Rocha"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"20e379523133ac64968983825835a7a7","permalink":"https://allansp84.github.io/publication/carvalho-2012-eri/","publishdate":"2021-03-19T18:19:14.008197Z","relpermalink":"/publication/carvalho-2012-eri/","section":"publication","summary":"An astonishing number of digital documents, such as digital pictures, videos, text files, etc., are daily produced and broadcasted. However, their authenticity is usually a doubtful question, since tampering digital documents have been become a simple task through using existent manipulation tools. So, our trust on digital documents is constantly decreasing, making necessary to develop effective approaches to recover this trust. All these facts highlight the importance of digital forensics in our day-by-day life. Based on this, our work presents a forensics computing overview showing main kind of forensics problems and most recently approaches to treat them.","tags":["Digital Image Forensics","Multimedia Forensics","Information Security"],"title":"VII Escola Regional de Inform√°tica de Minas Gerais","type":"publication"},{"authors":["Allan da Silva Pinto","Jorge Luiz e Silva"],"categories":null,"content":"","date":1230768000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1230768000,"objectID":"763f4cf9a98bdbffdc6d48904abf07a2","permalink":"https://allansp84.github.io/publication/pinto-2009-siicusp/","publishdate":"2021-03-19T18:19:14.010204Z","relpermalink":"/publication/pinto-2009-siicusp/","section":"publication","summary":"","tags":["Dataflow Architecture","FPGA","VHDL","Reconfigurable Computing"],"title":"ChipCflow - Uma Ferramenta para execu√ß√£o de Algoritmos Utilizando o Modelo a Fluxo de Dados Din√¢mico em Hardware Reconfigur√°vel-Circuito Matching e Instancias","type":"publication"}]