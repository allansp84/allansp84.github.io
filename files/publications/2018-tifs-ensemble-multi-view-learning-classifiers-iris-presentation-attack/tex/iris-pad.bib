% This file was created with JabRef 2.10.
% Encoding: ISO8859_1

@String { C_ACMMM    = {ACM Conference on Multimedia Systems} }
@String { C_AFGR     = {{IEEE} Intl. Conference and Workshops on Automatic Face and Gesture Recognition} }
@String { C_AVSS     = {{IEEE} Intl. Conference on Advanced Video and Signal Based Surveillance {(AVSS)}} }
@String { C_BIOSIG   = {Intl. Conference of the Biometrics Special Interest Group} }
@String { C_BTAS     = {{IEEE} Intl. Conference on Biometrics: Theory Applications and Systems} }
@String { C_BTHI     = {Biometric Technology for Human Identification} }
@String { C_CAIP     = {Computer Analysis of Images and Patterns} }
@String { C_CVPR     = {{IEEE} Intl. Conference on Computer Vision and Pattern Recognition} }
@String { C_CVPRW    = {{IEEE} Computer Society Conference on Computer Vision and Pattern Recognition Workshops} }
@String { C_DSP      = {Intl. Conference on Digital Signal Processing} }
@String { C_ECCV     = {European Conference on Computer Vision} }
@String { C_IASP     = {Intl. Conference on Image Analysis and Signal Processing} }
@String { C_ICANN    = {Intl. Conference on Artificial Neural Networks and Machine Learning} }
@String { C_ICARCV   = {Intl. Conference on Control Automation Robotics and Vision} }
@String { C_ICASSP   = {{IEEE} Intl. Conference on Acoustics, Speech, and Signal Processing} }
@String { C_ICB      = {IAPR Intl. Conference on Biometrics} }
@String { C_ICCV     = {{IEEE} Intl. Conference on Computer Vision} }
@String { C_ICIAP    = {Intl. Conference on Image Analysis and Processing} }
@String { C_ICIP     = {{IEEE} Intl. Conference on Image Processing} }
@String { C_ICMC     = {Intl. Conference on Multiple Classifier Systems} }
@String { C_ICMCS    = {Intl. Conference on Multimedia Computing and Systems} }
@String { C_ICML     = {Intl. Conference on Machine Learning} }
@String { C_ICMLC    = {Intl. Conference on Machine Learning and Cybernetics} }
@String { C_ICPAIR   = {Intl. Conference on Pattern Analysis and Intelligent Robotics} }
@String { C_ICPR     = {Intl. Conference on Pattern Recognition} }
@String { C_IJCB     = {{IEEE} Intl. Joint Conference on Biometrics} }
@String { C_SIBGRAPI = {{IEEE} Conference on Graphics, Patterns and Images} }
@String { J_ACMCS    = {ACM Comput. Surv.} }
@String { J_ACC      = {{IEEE} Access} }
@String { J_AES      = {{IEEE} Trans. Aerosp. Electron. Syst.} }
@String { J_C        = {J. Chemometrics} }
@String { J_CSDA     = {Computational Statistics \& Data Analysis} }
@String { J_CVIU     = {Computer Vision and Image Understanding} }
@String { J_IETB     = {IET Biometrics} }
@String { J_IJCV     = {Intl. Journal of Computer Vision} }
@String { J_IVC      = {Image and Vision Computing} }
@String { J_JIVP     = {EURASIP Journal on Image and Video Processing} }
@String { J_ML       = {Machine Learning} }
@String { J_PIEEE    = {Proc. IEEE} }
@String { J_PM       = {Philosophical Magazine} }
@String { J_PR       = {Pattern Recognition} }
@String { J_PRL      = {Pattern Recognition Letters} }
@String { J_SMC      = {{IEEE} Intl. Conference on Systems, Man and Cybernetics} }
@String { J_TBCS     = {{IEEE} Trans. Biomed. Circuits Syst.} }
@String { J_TIFS     = {{IEEE} Trans. Inf. Forens. Security} }
@String { J_TIP      = {{IEEE} Trans. Image Process.} }
@String { J_TIST     = {ACM Trans. Intelligent Systems and Technology} }
@String { J_TPAMI    = {{IEEE} Trans. Pattern Anal. Mach. Intell.} }
@String { J_TS       = {Telecommunication Systems} }
@String { J_TSMC     = {{IEEE} Trans. Syst. Man Cybern.} }
@String { J_WIRECS   = {WIREs Comp. Stat.} }
@String { W_ACCV     = {ACCV Intl. Workshops} }
@String { W_AIAT     = {{IEEE} Workshop on Automatic Identification Advanced Technologies} }
@String { W_BF       = {Intl. Workshop on Biometrics and Forensics } }
@String{C_ACCS     = {Int. Conference on Advanced Computing and Communication Systems}}
@String { C_ACMMM    = {ACM Conference on Multimedia Systems} }
@String { C_AFGR     = {{IEEE} Int. Conference and Workshops on Automatic Face and Gesture Recognition (FG)} }
@String{C_ASSP     = {{IEEE} Int. Conference on Acoustics, Speech and Signal Processing}}
@String { C_AVSS     = {{IEEE} Int. Conference on Advanced Video and Signal Based Surveillance (AVSS)} }
@String { C_BIDS     = {Int. Conference on Biometrics, Identity and Security (BIDS)} }
@String { C_BIOSIG   = {Int. Conference of the Biometrics Special Interest Group (BIOSIG)} }
@String { C_BMVC     = {British Machine Vision Conference (BMVC)} }
@String{C_BTAS     = {{IEEE} Int. Conference on Biometrics: Theory Applications and Systems (BTAS)}}
@String { C_BTHI     = {Biometric Technology for Human Identification (BTHI)} }
@String { C_CAIP     = {Int. Conference on Computer Analysis of Images and Patterns (CAIP)} }
@String{C_COMPSAC  = {{IEEE} Annual Computer Software and Applications Conference (COMPSAC)}}
@String{C_CRV      = {Int. Conference on Computer and Robot Vision (CRV)}}
@String { C_CVPR     = {{IEEE} Int. Conference on Computer Vision and Pattern Recognition (CVPR)} }
@String { C_CVPRW    = {{IEEE} Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)} }
@String { C_DSP      = {Int. Conference on Digital Signal Processing (DSP)} }
@String { C_ECCV     = {European Conference on Computer Vision (ECCV)} }
@String{C_EUSIPCO  = {European Signal Processing Conference (EUSIPCO)}}
@String{C_FedCSIS  = {Federated Conference on Computer Science and Information Systems (FedCSIS)}}
@String { C_IASP     = {Int. Conference on Image Analysis and Signal Processing (IASP)} }
@String { C_ICANN    = {Int. Conference on Artificial Neural Networks and Machine Learning (ICANN)} }
@String { C_ICARCV   = {Int. Conference on Control Automation Robotics and Vision (ICARCV)} }
@String { C_ICASSP   = {{IEEE} Int. Conference on Acoustics, Speech, and Signal Processing (ICASSP)} }
@String{C_ICB      = {{IEEE} Int. Conference on Biometrics (ICB)}}
@String{C_ICCCA    = {Int. Conference on Computing, Communication and Applications (ICCA)}}
@String{C_ICCSP    = {Int. Conference on Communication and Signal Processing (ICCSP)}}
@String{C_ICCST    = {{IEEE} Int. Carnahan Conference on Security Technology (ICCST)}}
@String { C_ICCV     = {{IEEE} Int. Conference on Computer Vision (ICCV)} }
@String { C_ICIAP    = {Int. Conference on Image Analysis and Processing (ICIAP)} }
@String{C_ICICT    = {Int. Conference on Inventive Computation Technologies (ICICT)}}
@String{C_ICIP     = {Int. {IEEE} International Conference on Image Processing}}
@String { C_ICMC     = {Int. Conference on Multiple Classifier Systems (ICMC)} }
@String { C_ICMCS    = {Int. Conference on Multimedia Computing and Systems (ICMCS)} }
@String { C_ICML     = {Int. Conference on Machine Learning (ICML)} }
@String { C_ICMLC    = {Int. Conference on Machine Learning and Cybernetics (ICMLC)} }
@String{C_ICMMAR   = {{IEEE} Int. Conference on Methods and Models in Automation and Robotics (MMAR)}}
@String { C_ICPAIR   = {Int. Conference on Pattern Analysis and Intelligent Robotics (ICPAIR)} }
@String { C_ICPR     = {Int. Conference on Pattern Recognition (ICPR)} }
@String{C_ICT      = {World Congress on Information and Communication Technologies}}
@String { C_IJCB     = {{IEEE} Int. Joint Conference on Biometrics (IJCB)} }
@String{C_IJCNN    = {{IEEE} Int. Joint Conference on Neural Networks (IJCNN)}}
@String{C_ISBA     = {{IEEE} Int. Conference on Identity, Security and Behavior Analysis (ISBA)}}
@String{C_ISCE     = {{IEEE} Int. Symposium on Consumer Electronics (ISCE)}}
@String{C_IWBF     = {Int. Conference on Biometrics and Forensics (IWBF)}}
@String{C_MIPRO    = {Int. Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)}}
@String{C_NCVPRIPG = {National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG)}}
@String{C_NRSC     = {National Radio Science Conference (NRSC)}}
@String{C_PDGC     = {Int. Conference on Parallel, Distributed and Grid Computing (PDGC)}}
@String{C_SCE      = {{IEEE} Int. Symposium on Consumer Electronics}}
@String { C_SIBGRAPI = {Conference on Graphics, Patterns and Images (SIBGRAPI)} }
@String{C_SICE     = {SICE Annual Conference}}
@String{C_SIN      = {Int. Conference on Security of Information and Networks}}
@String{C_SITIS    = {Int. Conference on Signal-Image Technology Internet-Based Systems (SITIS)}}
@String{C_SPMB     = {{IEEE} Signal Processing in Medicine and Biology Symposium (SPMB)}}
@String{C_TSP      = {Int. Conference on Telecommunications and Signal Processing (TSP)}}
@String{C_UIST     = {Annual ACM Symposium on User Interface Software and Technology}}
@String{C_UMT      = {Int. Conference on Ultra Modern Telecommunications \& Workshops}}
@String{C_VISAPP   = {{IEEE} Int. Conference on Computer Vision Theory and Applications (VISAPP)}}
@String{C_WACV     = {{IEEE} Winter Conference on Applications of Computer Vision (WACV)}}
@String{J_ACC      = {{IEEE} Access}}
@String { J_ACMCS    = {ACM Comput. Surv.} }
@String { J_AES      = {{IEEE} Trans. Aerosp. Electron. Syst.} }
@String{J_BTT      = {Biometric Technology Today}}
@String { J_C        = {J. Chemometrics} }
@String{J_CA       = {Int. Journal of Computer Applications}}
@String{J_CE       = {{IEEE} Trans. Consumer Electronics}}
@String{J_CEM      = {{IEEE} Consumer Electronics Magazine}}
@String{J_CGA      = {{IEEE} Computer Graphics and Applications}}
@String{J_COMPUTER = {{IEEE} Computer}}
@String { J_CSDA     = {Computational Statistics \& Data Analysis} }
@String { J_CVIU     = {Computer Vision and Image Understanding} }
@String { J_FGCS     = {Future Generation Computer Systems} }
@String { J_IETB     = {IET Biometrics} }
@String { J_IJCV     = {Int. Journal of Computer Vision} }
@String { J_IVC      = {Image and Vision Computing} }
@String{J_JFO      = {Journal of Forensic Sciences}}
@String { J_JIVP     = {EURASIP Journal on Image and Video Processing} }
@String{J_JTIT     = {Journal of Telecommunications and Information Technology}}
@String{J_LNCS     = {Lecture Notes in Computer Science}}
@String { J_ML       = {Machine Learning} }
@String{J_PIEEE    = {Proceedings of the {IEEE}}}
@String { J_PLOS     = {PLoS Computational Biology} }
@String { J_PM       = {Philosophical Magazine} }
@String{J_PR       = {Pattern Recognition}}
@String{J_PRL      = {Pattern Recognition Letters}}
@String{J_SEE      = {Science and Engineering Ethics}}
@String { J_SMC      = {{IEEE} Int. Conference on Systems, Man and Cybernetics} }
@String{J_SPM      = {{IEEE} Signal Processing Magazine}}
@String { J_TBCS     = {{IEEE} Trans. Biomed. Circuits Syst.} }
@String { J_TIFS     = {{IEEE} Trans. Inf. Forens. Security} }
@String { J_TIP      = {{IEEE} Trans. Image Process.} }
@String { J_TIST     = {ACM Trans. Intelligent Systems and Technology} }
@String { J_TPAMI    = {{IEEE} Trans. Pattern Anal. Mach. Intell.} }
@String { J_TS       = {Telecommunication Systems} }
@String { J_TSMC     = {{IEEE} Trans. Syst. Man Cybern.} }
@String { J_WIRECS   = {WIREs Comp. Stat.} }
@String{J_WMIP     = {Int. Journal of Wavelets, Multi-resolution and Information Processing}}
@String { W_ACCV     = {ACCV Int. Workshops} }
@String { W_AIAT     = {{IEEE} Workshop on Automatic Identification Advanced Technologies} }
@String { W_BF       = {Int. Workshop on Biometrics and Forensics } }
@String { W_BIOMS    = {{IEEE} Workshop on Biometric Measurements and Systems for Security and Medical Applications} }
@String{W_IFS      = {{IEEE} Int. Workshop on Information Forensics and Security}}
@String{W_WACV     = {{IEEE} Workshop on Applications of Computer Vision (WACV)}}

@article{Cortes:ML:1995,
 author = {Cortes, Corinna and Vapnik, Vladimir},
 title = {Support-Vector Networks},
 journal = {Mach. Learn.},
 issue_date = {Sept. 1995},
 volume = {20},
 number = {3},
 month = sep,
 year = {1995},
 issn = {0885-6125},
 pages = {273--297},
 numpages = {25},
 doi = {10.1023/A:1022627411411},
 acmid = {218929},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
}

@Book{Breiman:1984,
  Title                    = {Classification and regression trees},
  Author                   = {Breiman, L.},
  Publisher                = {Wadsworth International Group},
  Year                     = {1984},
  Series                   = {Wadsworth statistics/probability series},

  ISBN                     = {9780534980535},
  Lccn                     = {83019708}
}

@ARTICLE{Menotti:TIFS:2015, 
    author={D. Menotti and G. Chiachia and A. Pinto and W. R. Schwartz and H. Pedrini and A. X. Falc{\~{a}}o and A. Rocha}, 
    journal={IEEE Transactions on Information Forensics and Security}, 
    title={Deep Representations for Iris, Face, and Fingerprint Spoofing Detection}, 
    year={2015}, 
    volume={10}, 
    number={4}, 
    pages={864-879}, 
    doi={10.1109/TIFS.2015.2398817}, 
    ISSN={1556-6013}, 
    month={April},
}

@InCollection{NIPS2014_5423,
  Title                    = {Generative Adversarial Nets},
  Author                   = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  Booktitle                = {Advances in Neural Information Processing Systems 27},
  Publisher                = {Curran Associates, Inc.},
  Year                     = {2014},
  Editor                   = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
  Pages                    = {2672--2680},

  Url                      = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf}
}

@InProceedings{ioffe2015batch,
  Title                    = {Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  Author                   = {Ioffe, Sergey and Szegedy, Christian},
  Booktitle                = {Intl. Conference on Machine Learning},
  Year                     = {2015},
  Pages                    = {448--456}
}

@InProceedings{kannala2012bsif,
  Title                    = {{BSIF}: Binarized statistical image features},
  Author                   = {Kannala, Juho and Rahtu, Esa},
  Booktitle                = {Pattern Recognition (ICPR), 2012 21st Intl. Conference on},
  Year                     = {2012},
  Organization             = {IEEE},
  Pages                    = {1363--1366}
}

@Article{kittler1998combining,
  Title                    = {On combining classifiers},
  Author                   = {Kittler, Josef and Hatef, Mohamad and Duin, Robert PW and Matas, Jiri},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {1998},
  Number                   = {3},
  Pages                    = {226--239},
  Volume                   = {20},

  Publisher                = {IEEE}
}

@InCollection{kuncheva2014,
  Title                    = {Combining Label Outputs},
  Author                   = {Kuncheva, Ludmila I.},
  Pages                    = {111--142},
  Publisher                = {John Wiley \& Sons, Inc.},
  Year                     = {2014},
  Booktitle                = {Combining Pattern Classifiers},
  Doi                      = {10.1002/9781118914564.ch4},
  ISBN                     = {9781118914564},
  Keywords                 = {behavior knowledge space (BKS) combiner, label outputs, Naïve Bayes (NB) combiner, probabilistic framework},
  url                      = {http://dx.doi.org/10.1002/9781118914564.ch4},
}

@Article{othman2016osiris,
  Title                    = {{OSIRIS}: An open source iris recognition software},
  Author                   = {Othman, Nadia and Dorizzi, Bernadette and Garcia-Salicetti, Sonia},
  Journal                  = {Pattern Recognition Letters},
  Year                     = {2016},

  Month                    = oct,
  Number                   = {P2},
  Pages                    = {124--131},
  Volume                   = {82},

  Acmid                    = {3030461},
  Address                  = {New York, NY, USA},
  Doi                      = {10.1016/j.patrec.2015.09.002},
  ISSN                     = {0167-8655},
  Issue_date               = {October 2016},
  Keywords                 = {Iris normalization, Iris recognition, Non geometric parameterization of contours, OSIRIS, Open source system, Viterbi},
  Numpages                 = {8},
  Publisher                = {Elsevier Science Inc.},
  Url                      = {https://doi.org/10.1016/j.patrec.2015.09.002}
}


@article{Fleiss:EPM:1973,
    author = {Joseph L. Fleiss and Jacob Cohen},
    title ={The Equivalence of Weighted Kappa and the Intraclass Correlation Coefficient as Measures of Reliability},
    journal = {Educational and Psychological Measurement},
    volume = {33},
    number = {3},
    pages = {613-619},
    year = {1973},
    doi = {10.1177/001316447303300309},
}

@Article{Szegedy2013IntriguingPO,
    Title                    = {Intriguing properties of neural networks},
    Author                   = {Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian J. Goodfellow and Rob Fergus},
    Journal                  = {CoRR},
    Year                     = {2013},
    Volume                   = {abs/1312.6199}
}



@InProceedings{Daugman:SPIE:2014,
  Title                    = {{600 million citizens of India are now enrolled with biometric ID}},
  Author                   = {John Daugman},
  Booktitle                = {SPIE Newsroom},
  Year                     = {2014},
  Pages                    = {1--4},
  Doi                      = {https://doi.org/10.1117/2.1201405.005449}
}


@Misc{Nytimes,
  Title                    = {Cybersecurity Today Is Treated Like Accounting Before Enron University},

  Author                   = {The New York Times},
  HowPublished             = {\url{https://www.nytimes.com/2018/01/08/opinion/cybersecurity-breach-spectre-meltdown.html}},
  Note                     = {[Online; accessed 02/12/2018]},
  Year                     = {2018}
}

@Misc{GeorgeTownUniversity,
  Title                    = {Top 10 Threats to Information Security},

  Author                   = {GeorgeTown University},
  HowPublished             = {\url{https://scsonline.georgetown.edu/programs/masters-technology-management/resources/top-threats-to-information-technology}},
  Note                     = {[Online; accessed 02/12/2018]},
  Year                     = {2018},
}

@article{Yambay2014,
  title                     = {LivDet-iris 2013 - Iris Liveness Detection Competition 2013},
  author                    = {David Yambay and James S. Doyle and Kevin W. Bowyer and Adam Czajka and Stephanie Schuckers},
  journal                   = C_IJCB,
  year                      = {2014},
  pages                     = {1-8}
}

@article{Yambay2015,
  title                     = {LivDet-Iris 2015 - Iris Liveness Detection Competition 2015},
  author                    = {David Yambay and B. Walczak and Stephanie Schuckers and Adam Czajka},
  journal                   = {IEEE Intl. Conference on Identity, Security and Behavior Analysis (ISBA)},
  year                      = {2017},
  pages                     = {1-6}
}

@Article{Yambay2017,
  Title                    = {{LivDet 2017 - Iris Liveness Detection Competition 2017}},
  Author                   = {Yambay, David A. and Becker, Benedict and Kohli, Naman and Yadav, Daksha and Czajka, Adam and Bowyer, Kevin W. and Schuckers, Stephanie and Singh, Richa and Vatsa, Mayank and Noore, Afzel and Gragnaniello, D. and Sansone, C. and Verdoliva, L. and He, Lingshiao and Ru, Yiwei and Li, Haiqing and Liu, Nianfeng and Sun, Zhenan and Tan, Tieniu},
  Journal                  = {Biometrics: Theory Applications and Systems (BTAS)},
  Year                     = {2017},
  Pages                    = {0--5},

  Doi                      = {10.1109/BTAS.2014.6996283},
  ISBN                     = {9781479903108}
}

@article{Kohli2013,
  title         = {Revisiting iris recognition with color cosmetic contact lenses},
  author        = {Naman Kohli and Daksha Yadav and Mayank Vatsa and Richa Singh},
  journal       = {Intl. Conference on Biometrics (ICB)},
  year          = {2013},
  pages         = {1-7}
}

@article{Yadav2014,
  title         = {Unraveling the Effect of Textured Contact Lenses on Iris Recognition},
  author        = {Daksha Yadav and Naman Kohli and James S. Doyle and Richa Singh and Mayank Vatsa and Kevin W. Bowyer},
  journal       = J_TIFS,
  year          = {2014},
  volume        = {9},
  pages         = {851-862}
}

@article{Kohli2016,
  title         = {Detecting medley of iris spoofing attacks using DESIST},
  author        = {Naman Kohli and Daksha Yadav and Mayank Vatsa and Richa Singh and Afzel Noore},
  journal       = C_BTAS,
  year          = {2016},
  pages         = {1-6}
}

@article{Gupta2014,
  title         = {On Iris Spoofing Using Print Attack},
  author        = {Priyanshu Gupta and Shipra Behera and Mayank Vatsa and Richa Singh},
  journal       = {Pattern Recognition (ICPR), 2014 22nd Intl. Conference on},
  year          = {2014},
  pages         = {1681-1686}
}

@article{Doyle2015,
  title         = {Robust Detection of Textured Contact Lenses in Iris Recognition Using {BSIF}},
  author        = {James S. Doyle and Kevin W. Bowyer},
  journal       = {IEEE Access},
  year          = {2015},
  volume        = {3},
  pages         = {1672-1683}
}

@InProceedings{Moreno-Seco2006,
  author        = {Moreno-Seco, Francisco and I{\~{n}}esta, Jos{\'e} M. and de Le{\'o}n, Pedro J. Ponce and Mic{\'o}, Luisa},
  title         = {Comparison of Classifier Fusion Methods for Classification in Pattern Recognition Tasks},
  booktitle     = {Structural, Syntactic, and Statistical Pattern Recognition},
  year          = {2006},
  editor        = {Yeung, Dit-Yan and Kwok, James T. and Fred, Ana and Roli, Fabio and de Ridder, Dick},
  pages         = {705--713},
  address       = {Berlin, Heidelberg},
  publisher     = {Springer Berlin Heidelberg},
  __markedentry = {[akuehlka:6]},
  abstract      = {This work presents a comparison of current research in the use of voting ensembles of classifiers in order to improve the accuracy of single classifiers and make the performance more robust against the difficulties that each individual classifier may have. Also, a number of combination rules are proposed. Different voting schemes are discussed and compared in order to study the performance of the ensemble in each task. The ensembles have been trained on real data available for benchmarking and also applied to a case study related to statistical description models of melodies for music genre recognition.},
  isbn          = {978-3-540-37241-7},
}

@Misc{Condorcet1785,
  author  = {Condorcet, {Jean-Antoine-Nicolas de Caritat, Marquis de}},
  title   = {Essai sur l'application de l'analyse {\`{a}} la probabilit{\'{e}} des d{\'{e}}cisions rendus {\`{a}} la pluralit{\'{e}} des voix},
  year    = {1785},
  journal = {Imprimerie Royale Paris},
}

@Misc{livdet2017,
  title        = {{LivDet-Iris 2017 -- Iris Liveness Detection Competition}},
  howpublished = {Website},
  year         = {2017},
  note         = {Last access: 02/21/2018},
  url          = {http://iris2017.livdet.org/},
}

@article{breiman2001random,
    title={Random forests},
    author={Breiman, Leo},
    journal={Machine learning},
    volume={45},
    number={1},
    pages={5--32},
    year={2001},
    publisher={Springer}
}

@article{genuer2010variable,
    title={Variable selection using random forests},
    author={Genuer, Robin and Poggi, Jean-Michel and Tuleau-Malot, Christine},
    journal={Pattern Recognition Letters},
    volume={31},
    number={14},
    pages={2225--2236},
    year={2010},
    publisher={Elsevier}
}

@article{daugman1993high,
    title={High confidence visual recognition of persons by a test of statistical independence},
    author={Daugman, John G},
    journal={IEEE transactions on pattern analysis and machine intelligence},
    volume={15},
    number={11},
    pages={1148--1161},
    year={1993},
    publisher={IEEE}
}


@article{Daugman_PRS_2001,
    doi = {10.1098/rspb.2001.1696},
    year = {2001},
    title = {Epigenetic randomness, complexity and singularity of human iris patterns},
    abstract = {We investigated the randomness and uniqueness of human iris patterns by mathematically comparing 2.3 million different pairs of eye images. The phase structure of each iris pattern was extracted by demodulation with quadrature wavelets spanning several scales of analysis. The resulting distribution of phase sequence variation among different eyes was precisely binomial, revealing 244 independent degrees of freedom. This amount of statistical variability corresponds to an entropy (information density) of about 3.2 bits mm(-2) over the iris. It implies that the probability of two different irides agreeing by chance in more than 70% of their phase sequence is about one in 7 billion. We also compared images of genetically identical irides, from the left and right eyes of 324 persons, and from monozygotic twins. Their relative phase sequence variation generated the same statistical distribution as did unrelated eyes. This indicates that apart from overall form and colour, iris patterns are determined epigenetically by random events in the morphogenesis of this tissue. The resulting diversity, and the combinatorial complexity created by so many dimensions of random variation, mean that the failure of a simple test of statistical independence performed on iris patterns can serve as a reliable rapid basis for automatic personal identification},
    author = {Jonh Daugman and Cathryn Downing},
    journal = {Proceedings of the Royal Society B: Biological Sciences},
    volume = {268},
    number = {1477},
    pages = {1737-1740}
}

@INPROCEEDINGS{Bowyer_BTAS_2016, 
    author={K. W. Bowyer and P. J. Flynn}, 
    booktitle={IEEE Intl. Conference on Biometrics Theory, Applications and Systems (BTAS)}, 
    title={Biometric identification of identical twins: A survey}, 
    year={2016}, 
    volume={}, 
    number={}, 
    pages={1-8}, 
    abstract={The ability of biometric techniques to distinguish between identical twins is of interest for multiple reasons. The research literature touching on this topic is spread across a variety of areas. This survey pulls together the literature to date in this area, identifies available datasets for research, points out topics of uncertainty and suggests possible future research.}, 
    keywords={biometrics (access control);security of data;biometric identification;biometric uncertainty;identical twins;DNA;Databases;Face;Face recognition;Fingerprint recognition;Fingers}, 
    doi={10.1109/BTAS.2016.7791176}, 
    ISSN={}, 
    month={Sept},
}

@Misc{UIDAI,
  author        = {{Unique Identification Authority of India, Government of India}},
  Title                   = {{Unique Identification Authority of India Website}},
  HowPublished             = {\url{https://uidai.gov.in/}},
  Note                     = {[Online; accessed 02/12/2018]},
  Year                     = {2018}
}

@Misc{NEXUS_URL,
  author       = {{Canada Border Services Agency and U.S. Customs and Border Protection}},
  title        = {{NEXUS}},
  howpublished = {\url{https://www.cbsa-asfc.gc.ca/prog/nexus/menu-eng.html}},
  year         = {accessed January 19, 2018},
  abstract     = {This is the official Government of Canada NEXUS application website. NEXUS is designed to speed up border crossings for low-risk, pre-approved travellers into Canada and the United States (U.S.). It is jointly run by the Canada Border Services Agency and U.S. Customs and Border Protection.},
}

@InProceedings{Kannala_ICPR_2012,
  author    = {J. Kannala and E. Rahtu},
  title     = {BSIF: Binarized statistical image features},
  booktitle = {Intl. Conference on Pattern Recognition (ICPR)},
  year      = {2012},
  pages     = {1363-1366},
  month     = {Nov},
  issn      = {1051-4651},
  keywords  = {binary codes;feature extraction;image coding;image recognition;image representation;image segmentation;image texture;independent component analysis;BSIF;binarized statistical image features;binary code string;coordinate binarization;heuristic code constructions;histogram based image region representation;independent component analysis;linearly local image patch projection;local image descriptor construction;local phase quantization;modeling capacity;natural image statistics;natural images;pixel binary codes;texture information encoding;texture recognition;thresholding;Accuracy;Binary codes;Face recognition;Image recognition;Probes;Quantization;Vectors},
}

@Article{Doyle_IEEEAccess_2015,
  author   = {J. S. Doyle and K. W. Bowyer},
  title    = {Robust Detection of Textured Contact Lenses in Iris Recognition Using {BSIF}},
  journal  = J_ACC,
  year     = {2015},
  volume   = {3},
  pages    = {1672-1683},
  issn     = {2169-3536},
  abstract = {This paper considers three issues that arise in creating an algorithm for the robust detection of textured contact lenses in iris recognition images. The first issue is whether the accurate segmentation of the iris region is required in order to achieve the accurate detection of textured contact lenses. Our experimental results suggest that accurate iris segmentation is not required. The second issue is whether an algorithm trained on the images acquired from one sensor will well generalize to the images acquired from a different sensor. Our results suggest that using a novel iris sensor can significantly degrade the correct classification rate of a detection algorithm trained with the images from a different sensor. The third issue is how well a detector generalizes to a brand of textured contact lenses, not seen in the training data. This paper shows that a novel textured lens type may have a significant impact on the performance of textured lens detection.},
  comment  = {iris:PAD},
  doi      = {10.1109/ACCESS.2015.2477470},
  keywords = {image classification;image segmentation;image texture;iris recognition;object detection;BSIF;classification rate;iris recognition;iris region segmentation;iris sensor;robust textured contact lenses detection;Classification algorithms;Contact lenses;Detection algorithms;Detectors;Eyes;Image processing;Image segmentation;Iris recognition;Lenses;Biometrics;image classification;image processing;image texture analysis;machine learning},
}

@InProceedings{Daugman_IMAIP_2000,
  author    = {J. Daugman},
  title     = {Wavelet Demodulation Codes, Statistical Independence, and Pattern Recognition},
  booktitle = {Institute of Mathematics and its Applications, (IMA-IP)},
  year      = {2000},
  pages     = {244--260},
  abstract  = {Samples from stochastic signals with sufficient complexity need reveal only a little unexpected agreement, in order to reject the hypothesis that they are independent. The mere failure of a test of statistical independence can thereby serve as a basis for recognizing patterns confidently, provided they possess enough degrees-of-freedom. This paper discusses exploitation of this statistical principle in combination with wavelet image coding to extract phase descriptions of patterns. Demodulation and coarse quantization of the phase information creates decision environments characterized by well separated binomial-class distributions, and this lends itself to rapid and reliable pattern recognition. 1 Introduction The central issue in pattern recognition is the relationship between within-class variability and between-class variability. These are determined by the forms of variation (degrees-of-freedom) spanned by the pattern classes. Ideally the withinclass variability should be small.},
}

@Misc{Thalheim_CT_2002,
  author       = {Lisa Thalheim and Jan Krissler and Peter-Michael Ziegler},
  title        = {{Biometric Access Protection Devices and their Programs Put to the Test, Available online in c't Magazine, No. 11/2002, p. 114}},
  howpublished = {on-line},
  year         = {2002},
  abstract     = {Memorizing passwords is out. Laying your finger on a sensor or peering into a webcam can suffice to gain you immediate access to a system. There is the danger, however, that this new ease might be bought at the expense of security. How well do biometric access controls prevent unauthorized access? We have tested eleven products for you. According to estimates of the IBIA, the international organization of biometric devices and programs suppliers, worldwide turnover of biometric security devices and programs this year will for the first time exceed the 500 million euro limit. Though the growth is primarily being driven by large-scale orders by industrial customers and administrative bodies, nevertheless the number of products on the market designed for in-home and in-house PC use is rising. The range of biometric security access tools for PCs meanwhile extends from mice and keyboards with integrated fingerprint scanners to webcam solutions whose software is able to recognize the facial features of registered persons to scanners that make use of the distinct iris patters of humans for identifying individuals. When the PC is booted the security software that goes with the tool writes itself into the log-on routine expanding the latter to include biometric authentication. In many instances the screen saver is integrated into the routine thus allowing for biometric authentication after breaks from work while the PC is still running. Sophisticated solutions, moreover, permit biometry based security protection of specific programs and/or documents.},
}

@Article{Al-Raisi_TI_2008,
  author   = {Ahmad N. Al-Raisi and Ali M. Al-Khouri},
  title    = {Iris recognition and the challenge of homeland and border control security in UAE},
  journal  = {Telematics and Informatics},
  year     = {2008},
  volume   = {25},
  number   = {2},
  pages    = {117 - 132},
  issn     = {0736-5853},
  abstract = {This article discusses the implementation of iris recognition in improving the security of border control systems in the United Arab Emirates. The article explains the significance of the implemented solution and the advantages the government has gained to-date. The UAE deployment of iris recognition technology is currently the largest in the world, both in terms of number of Iris records enrolled (more than 840,751) and number of iris comparisons performed daily 6,225,761,155 (6.2 billion) in ‘all-against-all’ search mode.},
  doi      = {https://doi.org/10.1016/j.tele.2006.06.005},
  keywords = {Border control, Homeland security, Biometrics, Iris recognition},
  url      = {http://www.sciencedirect.com/science/article/pii/S0736585306000360},
}

@InProceedings{Doyle_ICB_2013,
  author    = {J. S. Doyle and P. J. Flynn and K. W. Bowyer},
  title     = {Automated classification of contact lens type in iris images},
  booktitle = C_ICB,
  year      = {2013},
  pages     = {1-6},
  month     = {June},
  abstract  = {Textured cosmetic lenses have long been known to present a problem for iris recognition. It was once believed that clear, soft contact lenses did not impact iris recognition accuracy. However, it has recently been shown that persons wearing clear, soft contact lenses experience an increased false non-match rate relative to persons not wearing contact lenses. Iris recognition systems need the ability to automatically determine if a person is (a) wearing no contact lens, (b) wearing a clear prescription lens, or (c), wearing a textured cosmetic lens. This work presents results of the first attempt that we are aware of to solve this three-class classification problem. Results show that it is possible to identify with high accuracy (96.5%) the images in which a textured cosmetic contact lens is present, but that correctly distinguishing between no lenses and soft lenses is a challenging problem.},
  doi       = {10.1109/ICB.2013.6612954},
  url       = {https://doi.org/10.1109/ICB.2013.6612954},
  issn      = {2376-4201},
  keywords  = {contact lenses;image classification;image texture;iris recognition;automated classification;iris images;iris recognition systems;prescription lens;soft contact lenses;textured cosmetic contact lens;Accuracy;Feature extraction;Iris;Iris recognition;Lenses;Training},
}

@InProceedings{HeXiaofu_ICB_2009,
  author    = {He, Xiaofu and Lu, Yue and Shi, Pengfei},
  title     = {A New Fake Iris Detection Method},
  booktitle = C_ICB,
  publisher = {Springer Berlin Heidelberg},
  year      = {2009},
  editor    = {Tistarelli, Massimo and Nixon, Mark S.},
  pages     = {1132--1139},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-01793-3},
  abstract  = {Recent research works have revealed that it is not difficult to spoof an automated iris recognition system using fake iris such as contact lens and paper print etc. Therefore, it is very important to detect fake iris as much as possible. In this paper, we propose a new fake iris detection method based on wavelet packet transform. First, wavelet packet decomposition is used to extract the feature values which provide unique information for discriminating fake irises from real ones. Second, to enhance the detecting accuracy of fake iris, Support vector machine (SVM) is used to characterize the distribution boundary based on extracted wavelet packet features, for it has good classification performance in high dimensional space and it is originally developed for two-class problems. The experimental results indicate the proposed method is to be a very promising technique for making iris recognition systems more robust against fake iris spoofing attempts.},
  doi       = {10.1007/978-3-642-01793-3_114},
  url       = {http://dx.doi.org/10.1007/978-3-642-01793-3_114},
}

@Article{Zuo_TIFS_2007,
  author   = {J. Zuo and N. A. Schmid and X. Chen},
  title    = {On Generation and Analysis of Synthetic Iris Images},
  journal  = J_TIFS,
  year     = {2007},
  volume   = {2},
  number   = {1},
  pages    = {77-90},
  month    = {March},
  issn     = {1556-6013},
  abstract = {The popularity of iris biometric has grown considerably over the past two to three years. It has resulted in the development of a large number of new iris encoding and processing algorithms. Since there are no publicly available large-scale and even medium-size data bases, neither of the newly designed algorithms has undergone extensive testing. The designers claim exclusively high recognition performance when the algorithms are tested on a small amount of data. In a large-scale setting, systems are yet to be tested. Since the issues of security and privacy slow down the speed of collecting and publishing iris data, an optional solution to the problem of algorithm testing is to synthetically generate a large scale data base of iris images. In this work, we describe a model-based method to generate iris images and evaluate the performance of synthetic irises by using a traditional Gabor filter-based iris recognition system. A comprehensive comparison of synthetic and real data is performed at three levels of processing: 1) image level, 2) texture level, and 3) decision level. A sensitivity analysis is performed to conclude on the importance of various parameters involved in generating iris images},
  doi      = {10.1109/TIFS.2006.890305},
  keywords = {Gabor filters;image coding;image recognition;image texture;Gabor filter-based iris recognition system;decision level;image level;iris encoding;iris processing algorithms;large-scale setting;model-based method;sensitivity analysis;synthetic iris images;texture level;Algorithm design and analysis;Biometrics;Data privacy;Data security;Encoding;Image analysis;Image generation;Iris;Large-scale systems;System testing;Biometrics;iris anatomy;iris-based authentication;performance extrapolation;texture analysis},
}




@InProceedings{Trokielewicz_BTAS_2016,
  author    = {M. Trokielewicz and A. Czajka and P. Maciejewicz},
  title     = {Human iris recognition in post-mortem subjects: Study and database},
  booktitle = C_BTAS,
  year      = {2016},
  pages     = {1-6},
  month     = {Sept},
  abstract  = {This paper presents a unique study of post-mortem human iris recognition and the first known to us database of near-infrared and visible-light iris images of deceased humans collected up to almost 17 days after death. We used four different iris recognition methods to analyze the dynamics of iris quality decay in short-term comparisons (samples collected up to 60 hours after death) and long-term comparisons (for samples acquired up to 407 hours after demise). This study shows that post-mortem iris recognition is possible and occasionally works even 17 days after death. These conclusions contradict a promulgated rumor that iris is unusable shortly after decease. We make this dataset publicly available to let others verify our findings and to research new aspects of this important and unfamiliar topic. We are not aware of any earlier papers offering post-mortem human iris images and such comprehensive analysis employing four different matchers.},
  doi       = {10.1109/BTAS.2016.7791175},
  keywords  = {eye;iris recognition;deceased humans;iris quality decay;near-infrared iris images;post-mortem human iris recognition;time 17 day;time 407 h;time 60 h;visible-light iris images;Biomedical imaging;Cameras;Cornea;Databases;Iris recognition},
}

@InProceedings{Komulainen_IJCB_2014,
  author    = {J. Komulainen and A. Hadid and M. Pietikäinen},
  title     = {Generalized textured contact lens detection by extracting BSIF description from Cartesian iris images},
  booktitle = C_IJCB,
  year      = {2014},
  pages     = {1-7},
  month     = {Sept},
  abstract  = {Textured contact lenses cause severe problems for iris biometric systems because they can be used to alter the appearance of iris texture in order to deliberately increase the false positive and, especially, false negative match rates. Many texture analysis based techniques have been proposed for detecting the presence of cosmetic contact lenses. However, it has been shown recently that the generalization capability of the existing approaches is not sufficient because they have been developed for detecting specific lens texture patterns and evaluated only on those same lens types seen during development phase. This scenario does not apply in unpredictable practical applications because unseen lens patterns will be definitely experienced in operation. In this paper, we address this issue by studying the effect of different iris image preprocessing techniques and introducing a novel approach formore generalized cosmetic contact lens detection using binarized statistical image features (BSIF).Our extensive experimental analysis on benchmark datasets shows that the BSIF description extracted from preprocessed Cartesian iris texture images yields to promising generalization capabilities across unseen texture patterns and different iris sensors with mean equal error rate of 0.14%and 0.88%, respectively. The findings support the intuition that the textural differences between genuine iris texture and fake ones are best described by preserving the regular structure of different printing signatures without transforming the iris images into polar coordinate system.},
  doi       = {10.1109/BTAS.2014.6996237},
  keywords  = {contact lenses;feature extraction;generalisation (artificial intelligence);image matching;image sensors;image texture;iris recognition;statistical analysis;BSIF description extraction;Cartesian iris texture images;binarized statistical image features;cosmetic contact lenses;false negative match rates;generalized cosmetic contact lens detection;generalized textured contact lens detection;iris image preprocessing techniques;lens texture pattern detection;mean equal error rate;polar coordinate system;texture analysis based techniques;Feature extraction;Iris;Iris recognition;Lenses;Printing;Support vector machines;Training},
}

@InCollection{Lovish_CAIP_2015,
  author    = {Lovish and A. Nigam and B. Kumar and P. Gupta},
  title     = {Robust Contact Lens Detection Using Local Phase Quantization and Binary Gabor Pattern},
  booktitle = C_CAIP,
  publisher = {Springer International Publishing},
  year      = {2015},
  editor    = {G. Azzopardi and N. Petkov},
  pages     = {702-714},
  isbn      = {978-3-319-23192-1},
  abstract  = {Due to its resistance to circumvention, iris has been used as a prime biometric trait in border crossings and identity related civil projects. However, sensor level spoofing attacks such as the use of printed iris, plastic eyeballs and contact lens pose a challenge by helping intruders to sidestep security in iris based biometric systems. Attacks through contact lenses are most challenging to detect as they obfuscate the iris partially and part of original iris remains visible through them. In this paper, we present a contact lens dataset containing 12823 images acquired from 50 subjects. Each subject has images pertaining to no lens, soft lens and cosmetic lens class. Verification results with three different techniques on three datasets suggest an average degradation of 3.10% in EER when subject is wearing soft lens and 17.34% when subject is wearing cosmetic lens. Further we propose a cosmetic lens detection approach based on Local Phase Quantization(LPQ) and Binary Gabor Pattern(BGP). Experiments conducted on publicly available IIITD Vista, IIITD Cogent, ND_2010 and self-collected dataset indicate that our method outperforms previous lens detection techniques in terms of Correct Classification Rate and false Acceptance Rate. The results suggest that a comprehensive texture descriptor having blur tolerance of LPQ and robustness of BGP is suitable for cosmetic lens detection.},
  comment   = {iris:PAD},
}

@InProceedings{Sequeira_TSP_2016,
  author    = {A. F. Sequeira and S. Thavalengal and J. Ferryman and P. Corcoran and J. S. Cardoso},
  title     = {A realistic evaluation of iris presentation attack detection},
  booktitle = C_TSP,
  year      = {2016},
  pages     = {660-664},
  month     = {June},
  abstract  = {Iris liveness detection methods have been developed to overcome the vulnerability of iris biometric systems to spoofing attacks. In the literature, it is typically assumed that a known attack modality will be perpetrated. Then liveness models are designed using labelled samples from both real/live and fake/spoof distributions, the latter derived from the assumed attack modality. In this work it is argued that a comprehensive modelling of the spoof samples is not possible in a real-world scenario where the attack modality cannot be known with a high degree of certainty. In fact making this assumption will render the liveness detection system more vulnerable to attacks that were not included in the original training. To provide a more realistic evaluation, this work proposes: a) testing the binary models with unknown spoof samples that were not present in the training step; b) the use of a single-class classification designing the classifier by modelling only the distribution of live samples. The results obtained support the assertion that many evaluation methods from the literature are misleading and may lead to optimistic estimates of the robustness of liveness detection in practical use cases.},
  doi       = {10.1109/TSP.2016.7760965},
  keywords  = {image classification;iris recognition;security of data;attack modality;binary models;iris biometric systems;iris liveness detection;iris presentation attack detection;single-class classification;spoof distributions;spoofing attacks;Biological system modeling;Databases;Iris recognition;Lenses;Testing;Training;Training data;biometrics;iris;one-class classification;presentation attack},
}

@InProceedings{Gragnaniello_SITIS_2014,
  author    = {D. Gragnaniello and G. Poggi and C. Sansone and L. Verdoliva},
  title     = {Contact Lens Detection and Classification in Iris Images through Scale Invariant Descriptor},
  booktitle = C_SITIS,
  year      = {2014},
  pages     = {560-565},
  month     = {Nov},
  abstract  = {We propose a new machine-learning technique for detecting the presence and type of contact lenses in iris images. Following the usual paradigm, we extract the regions of interest for classification, compute a feature vector based on local descriptors, and feed it to a properly trained SVM classifier. Major improvements w.r.t. Current state of the art concern the design of a more reliable segmentation procedure and the use of a recently proposed dense scale-invariant image descriptor. Experiments on publicly available datasets show the proposed method to outperform significantly all reference techniques.},
  doi       = {10.1109/SITIS.2014.35},
  keywords  = {contact lenses;feature extraction;image classification;iris recognition;learning (artificial intelligence);support vector machines;vectors;SVM classifier;contact lens classification;contact lens detection;feature vector;iris image;machine-learning technique;regions of interest extraction;scale invariant descriptor;Eyelids;Feature extraction;Image edge detection;Image segmentation;Iris;Iris recognition;Lenses;Contact lens classification;Iris biometrics;local descriptor},
}

@InProceedings{Akhtar_AVSS_2014,
  author    = {Z. Akhtar and C. Micheloni and C. Piciarelli and G. L. Foresti},
  title     = {MoBio\_LivDet: Mobile biometric liveness detection},
  booktitle = C_AVSS,
  year      = {2014},
  pages     = {187-192},
  month     = {Aug},
  abstract  = {Biometric authentication is now being used ubiquitously as an alternative to passwords on mobile devices. However, current biometric systems are vulnerable to simple spoofing attacks. Several liveness detection methods have been proposed to determine whether there is a live person or an artificial replica in front of the biometric sensor. Yet, the problem is unsolved due to hardship in finding discriminative and computationally inexpensive features for spoofing attacks. Moreover, previous liveness detection approaches are not explicitly aimed for mobile biometric, thus principally unsuited for portable devices. Therefore, we build a software-based multi-biometric prototype that detects face, iris and fingerprint spoofing attacks on mobile devices. We present MoBio_LivDet (Mobile Biometric Liveness Detection), a novel approach that analyzes local features and global structures of the biometric images using a set of low-level feature descriptors and decision level fusion. The system allows user to balance the security level (robustness against spoofing) and convenience that they want. The proposed method is highly fast, simple, efficient, robust and does not require user-cooperation, thus making it extremely apt for mobile devices. Experimental analysis on publicly available face, iris and fingerprint data sets with real spoofing attacks show promising results.},
  doi       = {10.1109/AVSS.2014.6918666},
  keywords  = {face recognition;fingerprint identification;image fusion;iris recognition;mobile computing;MoBio_LivDet;artificial replica;biometric authentication;biometric images;biometric sensor;decision level fusion;face detection;fingerprint spoofing attacks;global structures;iris detection;live person;local features;low-level feature descriptors;mobile biometric liveness detection;mobile devices;software-based multibiometric prototype;Face;Feature extraction;Fingerprint recognition;Iris recognition;Mobile communication;Mobile handsets;Support vector machines},
}

@Article{Gragnaniello_TIFS_2015,
  author   = {D. Gragnaniello and G. Poggi and C. Sansone and L. Verdoliva},
  title    = {An Investigation of Local Descriptors for Biometric Spoofing Detection},
  journal  = J_TIFS,
  year     = {2015},
  volume   = {10},
  number   = {4},
  pages    = {849-863},
  month    = apr,
  issn     = {1556-6013},
  abstract = {Biometric authentication systems are quite vulnerable to sophisticated spoofing attacks. To keep a good level of security, reliable spoofing detection tools are necessary, preferably implemented as software modules. The research in this field is very active, with local descriptors, based on the analysis of microtextural features, gaining more and more popularity, because of their excellent performance and flexibility. This paper aims at assessing the potential of these descriptors for the liveness detection task in authentication systems based on various biometric traits: fingerprint, iris, and face. Besides compact descriptors based on the independent quantization of features, already considered for some liveness detection tasks, we will study promising descriptors based on the joint quantization of rich local features. The experimental analysis, conducted on publicly available data sets and in fully reproducible modality, confirms the potential of these tools for biometric applications, and points out possible lines of development toward further improvements.},
  comment  = {iris:PAD, face:PAD, fingerprint:PAD},
  doi      = {10.1109/TIFS.2015.2404294},
}

@Article{Chen_PRL_2012,
  author   = {Rui Chen and Xirong Lin and Tianhuai Ding},
  title    = {Liveness detection for iris recognition using multispectral images},
  journal  = {Pattern Recognition Letters},
  year     = {2012},
  volume   = {33},
  number   = {12},
  pages    = {1513 - 1519},
  issn     = {0167-8655},
  abstract = {Liveness detection is a necessary step towards higher reliability of iris recognition. In this research, we propose a novel iris liveness detection method based on multi-features extracted from multispectral images. First, we analyze the specific multispectral characteristics of conjunctival vessels and iris textures. To ensure the effective utilization of these characteristics, iris images are simultaneously captured at near-infrared (860 nm) and blue (480 nm) wavelengths. Then we respectively define and measure relative number of conjunctival vessels (RNCV) and entropy ratio of iris textures (ERIT) using 860-nm and 480-nm images. Finally, the feature values of \{RNCV\} and \{ERIT\} are arranged to form a robust 2-D feature vector. The trained Support Vector Machine (SVM) is used to classify the feature vectors extracted from live and fake irises. Experimental results demonstrate that the proposed method can discriminate between live irises and various types of fake irises with high classification accuracy and low computational cost.},
  doi      = {https://doi.org/10.1016/j.patrec.2012.04.002},
  keywords = {Liveness detection, Multispectral images, Conjunctival vessel detection, Wavelet packet decomposition },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167865512001262},
}

@InProceedings{Silva_SIBGRAPI_2015,
  author       = {Silva, Pedro and Luz, Eduardo and Baeta, Rafael and Pedrini, Helio and Falc{\~{a}}o, Alexandre Xavier and Menotti, David},
  title        = {An Approach to Iris Contact Lens Detection based on Deep Image Representations},
  booktitle    = C_SIBGRAPI,
  year         = {2015},
  pages        = {157--164},
  month        = {August},
  organization = {IEEE},
  abstract     = {Spoofing detection is a challenging task in biometric systems, when differentiating illegitimate users from genuine ones. Although iris scans are far more inclusive than fingerprints, and also more precise for person authentication, iris recognition systems are vulnerable to spoofing via textured cosmetic contact lenses. Iris spoofing detection is also referred to as liveness detection (binary classification of fake and real images). In this work, we focus on a three-class detection problem: images with textured (colored) contact lenses, soft contact lenses, and no lenses. Our approach uses a convolutional network to build a deep image representation and an additional fully-connected single layer with soft max regression for classification. Experiments are conducted in comparison with a state-of-the-art approach (SOTA) on two public iris image databases for contact lens detection: 2013 Notre Dame and IIIT-Delhi. Our approach can achieve a 30% performance gain over SOTA on the former database (from 80% to 86%) and comparable results on the latter. Since IIIT-Delhi does not provide segmented iris images and, differently from SOTA, our approach does not segment the iris yet, we conclude that these are very promising results.},
  doi          = {10.1109/SIBGRAPI.2015.16},
  issn         = {1530-1834},
  keywords     = {authorisation;image representation;image segmentation;image texture;iris recognition;regression analysis;IIIT-Delhi;Notre Dame;SOTA;biometric systems;deep image representations;fully-connected single layer;illegitimate users;iris contact lens detection;iris recognition systems;iris scans;iris spoofing detection;liveness detection;person authentication;segmented iris images;soft contact lenses;softmax regression;state-of-the-art approach;textured cosmetic contact lenses;Databases;Image representation;Iris;Iris recognition;Lenses;Network topology;Training;Contact Lens Detection;Convolutional Networks;Deep Learning;Iris Biometrics},
}

@InProceedings{Gragnaniello_SITIS_2016,
  author    = {D. Gragnaniello and C. Sansone and G. Poggi and L. Verdoliva},
  title     = {Biometric Spoofing Detection by a Domain-Aware Convolutional Neural Network},
  booktitle = C_SITIS,
  year      = {2016},
  pages     = {193-198},
  month     = {Nov},
  abstract  = {Biometric authentication systems are pervasive in modern society, but they are quite vulnerable to spoofing attacks. Research on spoofing (or liveness) detection is therefore very active. A number of methods have been proposed in the literature, sometimes with very promising results, but limited robustness with respect to the large variety of biometric traits, sensors, and attacks encountered in real-life. Recently, methods based on Convolutional Neural Networks (CNNs) are drawing great attention, given their success in many other image processing tasks. However, despite some promising results, they seem to suffer the same robustness problem, requiring heavy training to work properly. Here, we propose a new CNN architecture for biometric spoofing detection. Thanks to domain-specific knowledge, accounted for through a suitable loss function, a compact architecture is obtained, allowing reliable training also in the presence of small-size datasets. Experiments prove the proposal to provide state-of-art performance on several widespread datasets for face and iris liveness detection.},
  doi       = {10.1109/SITIS.2016.38},
  keywords  = {face recognition;feedforward neural nets;iris recognition;learning (artificial intelligence);neural net architecture;visual databases;CNN architecture;biometric authentication systems;biometric spoofing detection;domain-aware convolutional neural network training;domain-specific knowledge;face detection;iris liveness detection;loss function;Biomedical imaging;Computer architecture;Convolution;Face;Feature extraction;Neurons;Training;Biometric spoofing;convolutional neural networks;liveness detection},
}

@InProceedings{He_BTAS_2016,
  author    = {L. He and H. Li and F. Liu and N. Liu and Z. Sun and Z. He},
  title     = {Multi-patch convolution neural network for iris liveness detection},
  booktitle = {IEEE Intl. Conference on Biometrics Theory, Applications and Systems (BTAS)},
  year      = {2016},
  pages     = {1-7},
  month     = {September},
  abstract  = {Attacking iris systems with fake iris patterns has become the largest security risk of iris recognition systems. Therefore iris liveness detection which discriminate genuine or fake iris images is of significant importance to iris recognition systems. However, the state-of-the-art algorithms mainly rely on hand-crafted texture features which can only identify fake iris images with single pattern. This paper proposes a Multi-patch Convolution Neural Network (MCNN) that is capable of handling different types of fake iris images. MCNN directly learns the mapping function between raw pixels of the input iris patch and the labels. The outputs of each patch are fed into a decision layer which determines the final decision. Our proposed algorithm automatically learns the features to detect hybrid pattern of fake iris images rather than handcraft. The decision layer helps to improve the robustness and accuracy for iris liveness detection. Experimental results demonstrate an extremely higher accuracy of iris liveness detection than other state-of-the-art algorithms. The proposed MCNN remarkably achieve the best results with nearly 100% accuracy on ND-Contact and CAISA-Iris-Fake datasets.},
  comment   = {iris:PAD},
  doi       = {10.1109/BTAS.2016.7791186},
  keywords  = {iris recognition;neural nets;decision layer;fake iris images;iris liveness detection;iris recognition systems;mapping function;multipatch convolution neural network;Algorithm design and analysis;Convolution;Feature extraction;Iris;Iris recognition;Lenses;Neural networks},
}

@InProceedings{Raghavendra_WACV_2017,
  author    = {R. Raghavendra and K. B. Raja and C. Busch},
  title     = {ContlensNet: Robust Iris Contact Lens Detection Using Deep Convolutional Neural Networks},
  booktitle = C_WACV,
  year      = {2017},
  pages     = {1160-1167},
  month     = {March},
  abstract  = {Contact lens detection in the eye is a significant task to improve the reliability of iris recognition systems. A contact lens overlays the iris region and prevents the iris sensor from capturing the normal iris region. In this paper, we present a novel scheme for detection to detecting a contact lens using Deep Convolutional Neural Network (CNN). The proposed CNN architecture ContlensNet is structured to have fifteen layers and configured for the three-class detection problem with the following classes: images with textured (or colored) contact lens, soft (or transparent) contact lens, and no contact lens. The proposed ContlensNet is trained using numerous iris image patches and the problem of overfitting the network is addressed by using the dropout regularization method. Extensive experiments are carried out on two publicly available large-scale databases, namely: IIIT-Delhi Contact lens iris database (IIITD) and Notre Dame cosmetic contact lens database 2013 (ND) that are comprised of contact lens iris samples captured using four different sensors. The obtained results have demonstrated the improved performance of the proposed scheme with an average performance improvement of more than 10% in Correct Classification Rate (CCR%) when compared with eight different state-of-the-art contact lens detection systems.},
  comment   = {iris:PAD},
  doi       = {10.1109/WACV.2017.134},
  keywords  = {Convolution;Databases;Image segmentation;Iris;Iris recognition;Lenses;Neural networks},
}

@InProceedings{Lee_BS_2006,
  author    = {S. J. Lee and K. R. Park and J. Kim},
  title     = {Robust Fake Iris Detection Based on Variation of the Reflectance Ratio Between the IRIS and the Sclera},
  booktitle = {Biometrics Symposium: Special Session on Research at the Biometric Consortium Conference},
  year      = {2006},
  pages     = {1-6},
  month     = {September},
  abstract  = {In this paper, we propose a new fake iris detection method based on the changes in the reflectance ratio between the iris and the sclera. The proposed method has four advantages over previous works. First, it is possible to detect fake iris images with high accuracy. Second, our method does not cause inconvenience to users since it can detect fake iris images at a very fast speed. Third, it is possible to show the theoretical background of using the variation of the reflectance ratio between the iris and the sclera. To compare fake iris images with live ones, three types of fake iris images were produced: a printed iris, an artificial eye, and a fake contact lens. In the experiments, we prove that the proposed fake iris detection method achieves high performance when distinguishing between live and fake iris.},
  comment   = {iris:PAD},
  doi       = {10.1109/BCC.2006.4341624},
  keywords  = {Authentication;Biometrics;Cameras;Fingerprint recognition;Fingers;Infrared imaging;Iris recognition;Reflectivity;Robustness;Waveguide discontinuities},
}

@Article{Park_OptEng_2007,
  author   = {Park, Jong Hyun and Kang, Moon Gi},
  title    = {Multispectral iris authentication system against counterfeit attack using gradient-based image fusion},
  journal  = {Optical Engineering},
  year     = {2007},
  volume   = {46},
  number   = {11},
  pages    = {117003-117003-14},
  abstract = {A new iris recognition scheme using multispectral iris images aimed for preventing the counterfeit attack is proposed. In the proposed system, multispectral infrared iris images are taken in order to utilize the spectral features of real iris. Rather than additionally deciding whether the enrolled iris is fake or not, the multispectral images are fused into a grayscale image to contain the complementary information among them by a gradient-based image fusion algorithm, and the iris region of the fused image is applied directly to the recognition procedure. Through the fusion process, the images which do not show multispectral variations result in a scrambled image that does not contain the exact features of the original iris. Because of the failure in the fusion process, the fused image of a fake iris does not match the original iris features in the database. Thus, they are simply rejected in the recognition step. Experimental results show that the proposed scheme successfully localizes the iris position of real irises and prevents possible counterfeit attacks while maintaining the performance of the authentication system.},
  comment  = {iris:PAD},
  doi      = {10.1117/1.2802367},
  isbn     = {0091-3286},
  url      = {http://dx.doi.org/10.1117/1.2802367},
}

@Article{Raja_TIFS_2015,
  author   = {K.B. Raja and R. Raghavendra and C. Busch},
  title    = {Video Presentation Attack Detection in Visible Spectrum Iris Recognition Using Magnified Phase Information},
  journal  = J_TIFS,
  year     = {2015},
  volume   = {10},
  number   = {10},
  pages    = {2048-2056},
  month    = {October},
  issn     = {1556-6013},
  abstract = {The gaining popularity of the visible spectrum iris recognition has sparked the interest in adopting it for various access control applications. Along with the popularity of visible spectrum iris recognition comes the threat of identity spoofing, presentation, or direct attack. This paper presents a novel scheme for detecting video presentation attacks in visible spectrum iris recognition system by magnifying the phase information in the eye region of the subject. The proposed scheme employs modified Eulerian video magnification (EVM) to enhance the subtle phase information in eye region and novel decision module to classify it as artefact(spoof attack) or normal presentation. The proposed decision module is based on estimating the change of phase information obtained from EVM, specially tailored to detect presentation attacks on video-based iris recognition systems in visible spectrum. The proposed scheme is extensively evaluated on the newly constructed database consisting of 62 unique iris video acquired using two smartphones-iPhone 5S and Nokia Lumia 1020. We also construct the artefact database with 62 iris acquired by replaying normal presentation iris video on iPad with retina display. Extensive evaluation of proposed presentation attack detection (PAD) scheme on the newly constructed database has shown an outstanding performance of average classification error rate = 0\% supporting the robustness of the proposed PAD scheme.},
  comment  = {iris:PAD},
  doi      = {10.1109/TIFS.2015.2440188},
}

@Article{Rigas_PRL_2015,
  author   = {Ioannis Rigas and Oleg V. Komogortsev},
  title    = {Eye movement-driven defense against iris print-attacks},
  journal  = J_PRL,
  year     = {2015},
  volume   = {68, Part 2},
  pages    = {316 - 326},
  issn     = {0167-8655},
  note     = {Special Issue on “Soft Biometrics”},
  abstract = {Abstract This paper proposes a methodology for the utilization of eye movement cues for the task of iris print-attack detection. We investigate the fundamental distortions arising in the eye movement signal during an iris print-attack, due to the structural and functional discrepancies between a paper-printed iris and a natural eye iris. The performed experiments involve the execution of practical print-attacks against an eye-tracking device, and the collection of the resulting eye movement signals. The developed methodology for the detection of print-attack signal distortions is evaluated on a large database collected from 200 subjects, which contains both the real (‘live’) eye movement signals and the print-attack (‘spoof’) eye movement signals. The suggested methodology provides a sufficiently high detection performance, with a maximum average classification rate (ACR) of 96.5% and a minimum equal error rate (EER) of 3.4%. Due to the hardware similarities between eye tracking and iris capturing systems, we hypothesize that the proposed methodology can be adopted into the existing iris recognition systems with minimal cost. To further support this hypothesis we experimentally investigate the robustness of our scheme by simulating conditions of reduced sampling resolution (temporal and spatial), and of limited duration of the eye movement signals.},
  doi      = {https://doi.org/10.1016/j.patrec.2015.06.011},
  keywords = {Eye movements, Anti-spoofing cues, Iris print-attack },
  url      = {http://www.sciencedirect.com/science/article/pii/S0167865515001737},
}

@Article{Czajka_TIFS_2015,
  author   = {Adam Czajka},
  title    = {Pupil Dynamics for Iris Liveness Detection},
  journal  = J_TIFS,
  year     = {2015},
  volume   = {10},
  number   = {4},
  pages    = {726-735},
  month    = {April},
  issn     = {1556-6013},
  abstract = {The primary objective of this paper is to propose a complete methodology for eye liveness detection based on pupil dynamics. This method may serve as a component of presentation attack detection in iris recognition systems, making them more secure. Due to a lack of public databases that would support this paper, we have built our own iris capture device to register pupil size changes under visible light stimuli, and registered 204 observations for 26 subjects (52 different irides), each containing 750 iris images taken every 40 ms. Each measurement registers the spontaneous pupil oscillations and its reaction after a sudden increase of the intensity of visible light. The Kohn and Clynes pupil dynamics model is used to describe these changes; hence we convert each observation into a feature space defined by model parameters. To answer the question whether the eye is alive (that is, if it reacts to light changes as a human eye) or the presentation is suspicious (that is, if it reacts oddly or no reaction is observed), we use linear and nonlinear support vector machines to classify natural reaction and spontaneous oscillations, simultaneously investigating the goodness of fit to reject bad modeling. Our experiments show that this approach can achieve a perfect performance for the data we have collected. All normal reactions are correctly differentiated from spontaneous oscillations. We investigated the shortest observation time required to model the pupil reaction, and found that time periods not exceeding 3 s are adequate to offer a perfect performance.},
  comment  = {iris:PAD:dynamic:active},
  doi      = {10.1109/TIFS.2015.2398815},
  keywords = {computer crime;feature extraction;image classification;iris recognition;support vector machines;eye liveness detection;feature space;iris capture device;iris images;iris liveness detection;iris recognition systems;model parameters;natural reaction classification;nonlinear support vector machines;presentation attack detection;pupil dynamics;pupil oscillations;pupil size changes;spontaneous oscillations;visible light intensity;visible light stimuli;Cameras;Databases;Iris recognition;Lenses;Motion pictures;Oscillators;Liveness detection;biometrics;iris recognition;presentation attack detection;pupil dynamics},
}

@Article{Thavalengal_TCE_2016,
  author   = {S. Thavalengal and T. Nedelcu and P. Bigioi and P. Corcoran},
  title    = {Iris liveness detection for next generation smartphones},
  journal  = J_CE,
  year     = {2016},
  volume   = {62},
  number   = {2},
  pages    = {95-102},
  month    = {May},
  issn     = {0098-3063},
  abstract = {This paper presents a novel liveness detection method that exploits the acquisition workflow for iris biometrics on smartphones using a hybrid visible (RGB)/near infra-red (NIR) sensor. These devices are able to capture both RGB and NIR images of the eye and iris region in synchronization. This multi-spectral information is mapped into a discrete feature space. An intermediate classifier which uses a distance metric close to Jenson-Shannon divergence is employed to classify the incoming image. Further, a fast, multi-frame pupil localization technique using one-dimensional processing of the eye region is proposed and evaluated. This is used to analyze the pupil characteristics of the images classified as 'live' in the previous stage. It is shown that such an analysis could detect presentation attacks, even with a 3-D face model made of materials that has properties similar to human skin and the ocular region1.},
  doi      = {10.1109/TCE.2016.7514667},
  keywords = {eye;face recognition;image capture;image classification;infrared detectors;iris recognition;smart phones;visible spectra;3D face model;Jenson-Shannon divergence;NIR image capture;NIR sensor;RGB image capture;RGB sensor;acquisition workflow;discrete feature space;distance metric;eye region;hybrid visible sensor;image classification;intermediate classifier;iris biometrics;iris liveness detection method;multiframe pupil localization technique;multispectral information mapping;near infrared sensor;next generation smartphone;one-dimensional processing;Authentication;Cameras;Hardware;Iris recognition;Smart phones;Smartphone;consumer biometrics;iris recognition;liveness},
}

@Misc{ISO_30107-1_2016,
  author  = {{ISO/IEC 30107-1:2016}},
  title   = {{Information technology -- Biometric presentation attack detection -- Part 1: Framework}},
  comment = {standards:PAD:ISO},
}

@Misc{ISO_30107-3_2017,
  author  = {{ISO/IEC FDIS 30107-3:2017}},
  title   = {{Information technology -- Biometric presentation attack detection -- Part 3: Testing and reporting}},
  comment = {standards:PAD:ISO},
}

@InProceedings{Pacut_ICCST_2006,
  author    = {A. Pacut and A. Czajka},
  title     = {Aliveness Detection for Iris Biometrics},
  booktitle = C_ICCST,
  year      = {2006},
  pages     = {122-129},
  month     = {October},
  abstract  = {Various experiments show an alarming lack of anti-spoofing mechanisms in devices already protecting many sensitive areas all over the world, proving that aliveness detection methods must be quickly included in commercial equipment. To introduce and systemize the topic, the paper begins with a survey of possible types of eye forgery, together with possible countermeasures. The authors introduce three solutions of eye aliveness detection, based on analyses of image frequency spectrum, controlled light reflection from the cornea, and pupil dynamics. A body of various fake (printed) eye images was used to test the developed methodologies, including different printers and printout carriers. The proposed methodology was embedded into the NASK iris recognition system and showed its large potential. For a local database of pairs of alive and printed eyes, all methods proposed in the paper revealed zero false acceptance rate of fakes FAR-F. The false rejection rate of genuines FRR-G reached 2.8% for the first proposed solution, and showed null value for the next two proposed methods. This very favorable compares to the commercial equipment tested: two popular iris cameras accepted 73% and 15% of the prepared fake irises.},
  comment   = {iris:PAD},
  doi       = {10.1109/CCST.2006.313440},
  issn      = {1071-6572},
  keywords  = {biometrics (access control);eye;image recognition;aliveness detection;anti-spoofing mechanisms;biometrics;eye forgery;false acceptance rate of fakes;false rejection rate of genuines;image frequency spectrum;iris recognition;light reflection;pupil dynamics;Biometrics;Cornea;Forgery;Frequency;Image analysis;Iris;Lighting control;Optical reflection;Protection;Testing;aliveness detection;biometrics;iris recognition},
}

@Article{Lee_IMA_2010,
  author    = {Lee, Eui Chul and Park, Kang Ryoung},
  title     = {Fake iris detection based on {3D} structure of iris pattern},
  journal   = {Intl. Journal of Imaging Systems and Technology},
  year      = {2010},
  volume    = {20},
  number    = {2},
  pages     = {162--166},
  issn      = {1098-1098},
  abstract  = {A new fake iris detection method based on 3D feature of iris pattern is proposed. In pervious researches, they did not consider 3D structure of iris pattern, but only used 2D features of iris image. However, in our method, by using four near infra-red (NIR) illuminators attached on the left and right sides of iris camera, we could obtain the iris image in which the 3D structure of iris pattern could be shown distinctively. Based on that, we could determine the live or fake iris by wavelet analysis of the 3D feature of iris pattern. Experimental result showed that the Equal Error Rate (EER) of determining the live or fake iris was 0.33%.},
  doi       = {10.1002/ima.20227},
  keywords  = {fake iris detection, 3D feature of iris pattern, wavelet analysis},
  publisher = {Wiley Subscription Services, Inc., A Wiley Company},
  url       = {http://dx.doi.org/10.1002/ima.20227},
}

@InProceedings{Pala_CVPR_2017,
  author    = {Pala, Federico and Bhanu, Bir},
  title     = {Iris Liveness Detection by Relative Distance Comparisons},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  year      = {2017},
  month     = {July},
  abstract  = {The focus of this paper is on presentation attack de- tection for the iris biometrics, which measures the pattern within the colored concentric circle of the subjects’ eyes, to authenticate an individual to a generic user verification system. Unlike previous deep learning methods that use sin- gle convolutional neural network architectures, this paper develops a framework built upon triplet convolutional net- works that takes as input two real iris patches and a fake patch or two fake patches and a genuine patch. The aim is to increase the number of training samples and to gen- erate a representation that separates the real from the fake iris patches. The smaller architecture provides a way to do early stopping based on the liveness of single patches rather than the whole image. The matching is performed by com- puting the distance with respect to a reference set of real and fake examples. The proposed approach allows for real- time processing using a smaller network and provides equal or better than state-of-the-art performance on three bench- mark datasets of photo-based and contact lens presentation attacks.},
}

@InBook{Galbally_Handbook_2016,
  pages     = {469--496},
  title     = {Iris Image Reconstruction from Binary Templates},
  publisher = {Springer London},
  year      = {2016},
  author    = {Galbally, Javier and Savvides, Marios and Venugopalan, Shreyas and Ross, Arun A.},
  editor    = {Bowyer, Kevin W. and Burge, Mark J.},
  address   = {London},
  isbn      = {978-1-4471-6784-6},
  abstract  = {This chapter explores the possibility of recovering iris images from binary iris templates. It has been generally assumed that the binary iris code is irreversible, i.e., the original iris texture cannot be derived from it. Here, we discuss two distinct approaches to reconstruct the iris texture from the binary iris code. Next, we discuss a method to detect such synthesized iris textures. Finally, we discuss some of the advantages and risks of generating iris texture from iris codes in the context of data privacy and security.},
  booktitle = {Handbook of Iris Recognition},
  doi       = {10.1007/978-1-4471-6784-6_20},
  url       = {http://dx.doi.org/10.1007/978-1-4471-6784-6_20},
}

@InProceedings{Connell_ASSP_2013,
  author    = {J. Connell and N. Ratha and J. Gentile and R. Bolle},
  title     = {Fake iris detection using structured light},
  booktitle = C_ASSP,
  year      = {2013},
  pages     = {8692-8696},
  month     = {May},
  abstract  = {Iris recognition has gained popularity due to factors such as its perceived high accuracy, significant usability advantages attributed to its non-contact acquisition method, and the availability of low cost sensors due to improvements in technology. However, non-contact biometrics authentication systems are vulnerable to different types of attacks than contact-type biometrics, such as fingerprints, for which there are a number of simple techniques to guard against attacks. In particular, the fashion industry has developed designer contact lenses with patterns that range from a simple change in eye color to the imposition of stars or other festive decorations. As these lenses are readily available and can be personalized at a very affordable price, their use in thwarting or spoofing iris-based authentication systems becomes plausible. Given the high security nature of many of these systems, there is a urgent need for a some countermeasure to this type of attack. In this paper, we describe a novel method to detect the presence of fake iris patterns, such as designer contact lenses, during the image acquisition stage to further enhance the basic security value of iris biometrics. Exploiting the anatomy and geometry of the human eye, we present a structured light projection method to detect the presence of artificial items obscuring the real iris. The detection principle has been verified using an inexpensive experimental setup consisting of a miniature projector and an offset camera. We also describe a novel algorithm to process the acquired images to find patterned contact lenses, and measure its performance using data collected with our apparatus. We argue that the addition of the proposed system and algorithm to existing iris biometrics based authentication systems will significantly improve their security.},
  comment   = {iris:PAD},
  doi       = {10.1109/ICASSP.2013.6639363},
  issn      = {1520-6149},
  keywords  = {iris recognition;designer contact lens;fake iris detection;fake iris pattern;image acquisition;iris based authentication system;iris biometrics;iris recognition;noncontact biometrics authentication system;structured light projection method;Authentication;Iris;Iris recognition;Lenses;Pattern recognition;designer contact lenses;iris recognition;spoofing iris acquisition;structured light projection},
}

@InProceedings{Hughes_HICSS_2013,
  author    = {K. Hughes and K. W. Bowyer},
  title     = {Detection of Contact-Lens-Based Iris Biometric Spoofs Using Stereo Imaging},
  booktitle = {Hawaii Intl. Conference on System Sciences},
  year      = {2013},
  pages     = {1763-1772},
  month     = {January},
  comment   = {iris:PAD},
  doi       = {10.1109/HICSS.2013.172},
  issn      = {1530-1605},
  keywords  = {Cameras;Cornea;Image segmentation;Iris;Iris recognition;Lenses;Shape;biometrics;contact lenses;identify theft;iris recognition;spoof detection},
}

@article{Nguyen_2018, 
    title={Deep Learning-Based Enhanced Presentation Attack Detection for Iris Recognition by Combining Features from Local and Global Regions Based on NIR Camera Sensor}, 
    volume={18}, 
    ISSN={1424-8220}, 
    url={http://dx.doi.org/10.3390/s18082601},
    DOI={10.3390/s18082601}, 
    number={8}, 
    journal={Sensors}, 
    publisher={MDPI AG}, 
    author={Nguyen, Dat and Pham, Tuyen and Lee, Young and Park, Kang}, 
    year={2018}, 
    month={Aug}, 
    pages={2601}
}

@inproceedings{kontschieder2015deep,
    title={Deep neural decision forests},
    author={Kontschieder, Peter and Fiterau, Madalina and Criminisi, Antonio and Rota Bulo, Samuel},
    booktitle=C_ICCV,
    pages={1467--1475},
    year={2015}
}

@article{Czajka_CSUR_2018,
 author = {Czajka, Adam and Bowyer, Kevin W.},
 title = {Presentation Attack Detection for Iris Recognition: An Assessment of the State-of-the-Art},
 journal = {ACM Comput. Surv.},
 issue_date = {August 2018},
 volume = {51},
 number = {4},
 month = jul,
 year = {2018},
 issn = {0360-0300},
 pages = {86:1--86:35},
 articleno = {86},
 numpages = {35},
 url = {http://doi.acm.org/10.1145/3232849},
 doi = {10.1145/3232849},
 acmid = {3232849},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Presentation attack detection, anti-spoofing, iris recognition, liveness detection},
}