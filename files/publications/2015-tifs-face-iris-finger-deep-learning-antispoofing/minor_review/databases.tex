%!TEX root = 2014-TIFS-dl-spoofing.tex
\section{Benchmarks}
\label{sec:databases}

In this section, we describe the benchmarks (datasets) that we consider in this work. All them are publicly available upon request and suitable for evaluating countermeasure methods to iris, face and fingerprint spoofing attacks. Table~\ref{tab:databases} shows the major features of each one and in the following we describe their details.


\begin{table*}[tb!]
\begin{center}
\caption{Main features of the benchmarks considered herein.}
\label{tab:databases}
%\tiny  \scriptsize \footnotesize \small \normalsize     
\iffinal
%\small
\else
\tiny
\fi
\begin{tabular}{clccrrrcrrrcrrr}
\hline
\multirow{2}{*}{Modality}
& \multirow{2}{*}{Benchmark/Dataset}
                                            & \multirow{2}{*}{Color}
                                                    &      Dimension
                                                                         &\multicolumn{3}{c}{\# Training}
                                                                                               && \multicolumn{3}{c}{\# Testing} 
                                                                                                                     && \multicolumn{3}{c}{\# Development} \\
\cline{5-7}\cline{9-11}\cline{13-15}
&                                            &       & $cols \times rows$ & Live & Fake & Total && Live & Fake & Total && Live & Fake & Total \\
\hline
\hline
\multirow{3}{*}{Iris}
&Warsaw~\cite{Czajka:MMAR:2013}              & No    & $640 \times  480$ &  228 &  203 &   431 &&  624 &  612 &  1236 \\
&Biosec~\cite{Ruiz-Albacete:BIOID:2008}      & No    & $640 \times  480$ &  200 &  200 &   400 &&  600 &  600 &  1200 \\
&MobBIOfake~\cite{Sequeira:VISAPP:2014:base} & Yes   & $250 \times  200$ &  400 &  400 &   800 &&  400 &  400 &   800 \\
\hline
\multirow{2}{*}{Face}
& Replay-Attack~\cite{Chakka:IJCB:2011}      & Yes   & $320 \times  240$ &  600 & 3000 &  3600 && 4000 &  800 &  4800 &&  600 & 3000 & 3600 \\
& 3dMad~\cite{Chingovska:ICB:2013}           & Yes   & $640 \times  480$ &  350 &  350 &   700 &&  250 &  250 &   500 &&  250 &  250 &  500 \\
\hline
\multirow{4}{*}{Fingerprint} 
&Biometrika~\cite{Ghiani:ICB:2013}           & No    & $312 \times  372$ & 1000 & 1000 &  2000 && 1000 & 1000 &  2000 \\
&CrossMatch~\cite{Ghiani:ICB:2013}           & No    & $800 \times  750$ & 1250 & 1000 &  2250 && 1250 & 1000 &  2250 \\
&Italdata~\cite{Ghiani:ICB:2013}             & No    & $640 \times  480$ & 1000 & 1000 &  2000 && 1200 & 1000 &  2000 \\
&Swipe~\cite{Ghiani:ICB:2013}                & No    & $208 \times 1500$ & 1221 &  979 &  2200 && 1153 & 1000 &  2153 \\
\hline

\end{tabular}
\end{center}
\end{table*}

\subsection{Iris Spoofing Benchmarks}

\subsubsection{Biosec} 
This benchmark was created using iris images from $50$ users of the BioSec~\cite{Ruiz-Albacete:BIOID:2008}.
In total, there are $16$ images for each user ($2$ sessions $\times$ $2$ eyes $\times$ $4$ images), totalizing $800$ valid access images. 
To create spoofing attempts, the original images from Biosec were preprocessed to improve quality and printed using an HP Deskjet 970cxi and an HP LaserJet 4200L printers. 
Finally, the iris images were recaptured with the same iris camera used to capture the original images.

\subsubsection{Warsaw} 
This benchmark contains $1274$ images of $237$ volunteers representing valid accesses and $729$ printout images representing spoofing attempts, which were generated by using two printers: (1) a HP LaserJet 1320 used to produce $314$ fake images with $600$ dpi resolution, and (2) a Lexmark C534DN used to produce $415$ fake images with $1200$ dpi resolution. Both real and fake images were captured by an IrisGuard AD100 biometric device.

\subsubsection{MobBIOfake} 
This benchmark contains live iris images and fake printed iris images captured with the same acquisition sensor, i.e., a mobile phone. To generate fake images, the authors first performed a preprocessing in the original images to enhance the contrast. The preprocessed images were then printed with a professional printer on high quality photographic paper.
%Os autores n√£o forneceram mais dados sobre este dataset.


\subsection{Video-based Face Spoofing Benchmarks}

\subsubsection{Replay-Attack} 
This benchmark contains short video recordings of both valid accesses and video-based attacks of $50$ different subjects. 
To generate valid access videos, each person was recorded in two sessions in a controlled and in an adverse environment with a regular webcam.
Then, spoofing attempts were generated using three techniques:
(1)~\emph{print attack}, which presents to the acquisition sensor hard copies of high-resolution digital photographs printed with a Triumph-Adler DCC 2520 color laser printer; 
(2) \emph{mobile attack}, which presents to the acquisition sensor photos and videos taken with an iPhone using the iPhone screen; 
and (3) \emph{high-definition attack}, in which high resolution photos and videos taken with an iPad are presented to the acquisition sensor using the iPad screen.
%In total, there is $200$ valid access videos and $1000$ spoofing attack videos.

\subsubsection{3DMAD} 
This benchmark consists of real videos and fake videos made with people wearing masks. A total of $17$ different subjects were recorded with a Microsoft Kinect sensor, and videos were collected in three sessions. For each session and each person, five videos of $10$ seconds were captured. The 3D masks were produced by \url{ThatsMyFace.com} using one frontal and two profile images of each subject.
All videos were recorded by the same acquisition sensor.
%In total, there are 85 valid access videos and 85 faces. 
%\ToDo{Allan: how many videos? 85 videos de acesso v√°lido e 85 fakes}


\subsection{Fingerprint Spoofing Benchmarks}

\subsubsection{LivDet2013} 
This dataset contains four sets of real and fake fingerprint readings performed in four acquisition sensors: Biometrika FX2000, Italdata ET10, Crossmatch L Scan Guardian, and Swipe.
For a more realistic scenario, fake samples in Biometrika and Italdata were generated without user cooperation, while fake samples in Crossmatch and Swipe were generated with user cooperation. 
Several materials for creating the artificial fingerprints were used, including gelatin, silicone, latex, among others. 
%Both Biometrika and Italdata sets are composed of $1000$ real images and $1000$ fake images. 
%Already, Crossmatch and Swipe sets are composed of $1250$ real images and $1250$ fake images\footnote{those are the figures reported on the public works, but the real number used in this work is slightly different for the Swipe Dataset}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Remark}

% The benchmarks described in this section aim at evaluating the proposed method considering a more realistic scenario, given that heterogeneity of the datasets is a challenge, mainly for algorithms based on machine learning, due to difficulty of finding a generalizable model.

Images found in these benchmarks can be observed in Fig.~\ref{fig:datasets} of Section~\ref{sec:experiments}. 
As we can see, variability exists not only across modalities, but also within modalities. Moreover, it is rather unclear what features might discriminate real from spoofed images, which suggests that the use of a methodology able to use data to its maximum advantage might be a promising idea to tackle such set of problems in a principled way.

% Methods developed to work on some database using specific features might not perform well on other databases of the same problem. 
% This hard scenario hints the use of the proposed framework which aims to learn deep representations from the data of each database such that promising effectiveness is expected to be achieved.




% Even considering each modality alone, we have data from many different sensors, which complicates the problem of detecting an attempted attack, and different modes of spoofing attacks, using different types of equipment and procedures. 

% To have an idea of the difficulty of this problem, consider the images depicted in Fig.~\ref{fig:datasets} (linked to Section~\ref{sec:experiments}).
%\TODO{essa referencia de pagina talvez seja perdida na versao final, melhor deixar apenas o numero da figura}. 
%pp.~\pageref{page:fig:datasets}
% Menotti: concordo que a p·gina n„o È o melhor artÌfico, mas a figura est· muito longe, por isso usei "linked to Section~\ref{sec:discussion}
% Observe the high variability even within the same modalities. 
%\question{Experiments in this hard scenario hints at the performance of the proposed framework in a more realistic and operational scenario}%
%{Sentenca confusa, nao estah claro qual eh a conclusao que se queria ter com essa sentenca.}. 
%suggestion
% Methods developed to work on some database using specific features might not perform well on other databases of the same problem. 
% This hard scenario hints the use of the proposed framework which aims to learn deep representations from the data of each database such that promising effectiveness is expected to be achieved.

% In the next section, we describe details of our framework for  spoofing attack detection under different modalities. 
% We shall return to the details in such figure when discussing the experimental results. 

% 